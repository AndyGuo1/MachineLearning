# 梯度下降
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/01-Week1/4-Parameter Learning/1-Gradient Descent.mp4" type="video/mp4">
</video>
## 中文
### 梯度下降算法
![梯度下降算法](amWiki/images/001/01-Week1/4-Parameter Learning/1_梯度下降算法.jpg)
我们已经定义了代价函数J 而在这段视频中 我想向你们介绍梯度下降这种算法 这种算法可以将代价函数J最小化 梯度下降是很常用的算法 它不仅被用在线性回归上 它实际上被广泛的应用于机器学习领域中的众多领域 在后面课程中 为了解决其他线性回归问题 我们也将使用梯度下降法 最小化其他函数 而不仅仅是只用在本节课的代价函数J 因此在这个视频中 我将讲解用梯度下降算法最小化函数 J 在后面的视频中 我们还会将此算法应用于具体的 代价函数J中来解决线性回归问题 下面是问题概述 在这里 我们有一个函数J(θ0, θ1) 也许这是一个线性回归的代价函数 也许是一些其他函数 要使其最小化 我们需要用一个算法 来最小化函数J(θ0, θ1) 就像刚才说的 事实证明 梯度下降算法可应用于 多种多样的函数求解 所以想象一下如果你有一个函数 J(θ0, θ1, θ2, ...,θn ) 你希望可以通过最小化 θ0到θn 来最小化此代价函数J(θ0 到θn) 用n个θ是为了证明梯度下降算法可以解决更一般的问题 但为了简洁起见 为了简化符号 在接下来的视频中 我只用两个参数 下面就是关于梯度下降的构想 我们要做的是 我们要开始对θ0和θ1 进行一些初步猜测 它们到底是什么其实并不重要 但通常的选择是将 θ0设为0 将θ1也设为0 将它们都初始化为0 我们在梯度下降算法中要做的 就是不停地一点点地改变 θ0和θ1 试图通过这种改变使得J(θ0, θ1)变小 直到我们找到 J 的最小值 或许是局部最小值
### 梯度下降法是如何工作的？
![梯度下降法是如何工作的](amWiki/images/001/01-Week1/4-Parameter Learning/2_梯度下降法是如何工作的.jpg)
让我们通过一些图片来看看梯度下降法是如何工作的 我在试图让这个函数值最小 注意坐标轴 θ0和θ1在水平轴上 而函数 J在垂直坐标轴上 图形表面高度则是 J的值 我们希望最小化这个函数 所以我们从 θ0和θ1的某个值出发 所以想象一下 对 θ0和θ1赋以某个初值 也就是对应于从这个函数表面上的某个起始点出发 对吧 所以不管 θ0和θ1的取值是多少 我将它们初始化为0 但有时你也可把它初始化为其他值 现在我希望大家把这个图像想象为一座山 想像类似这样的景色 公园中有两座山 想象一下你正站立在山的这一点上 站立在你想象的公园这座红色山上 在梯度下降算法中 我们要做的就是旋转360度 看看我们的周围 并问自己 我要在某个方向上 用小碎步尽快下山 如果我想要下山 如果我想尽快走下山 这些小碎步需要朝什么方向? 如果我们站在山坡上的这一点 你看一下周围 ​​你会发现最佳的下山方向 大约是那个方向 好的 现在你在山上的新起点上 你再看看周围 然后再一次想想 我应该从什么方向迈着小碎步下山? 然后你按照自己的判断又迈出一步 往那个方向走了一步 然后重复上面的步骤 从这个新的点 你环顾四周 并决定从什么方向将会最快下山 然后又迈进了一小步 又是一小步 并依此类推 直到你接近这里 直到局部最低点的位置 此外 这种下降有一个有趣的特点 第一次我们是从这个点开始进行梯度下降算法的 是吧 在这一点上从这里开始
### 不同初始化值得到不同的局部最优解
![不同初始化值得到不同的局部最优解](amWiki/images/001/01-Week1/4-Parameter Learning/3_不同初始化值得到不同的局部最优解.jpg)
现在想象一下 我们在刚才的右边一些的位置 对梯度下降进行初始化 想象我们在右边高一些的这个点 开始使用梯度下降 如果你重复上述步骤 停留在该点 并环顾四周 往下降最快的方向迈出一小步 然后环顾四周 又迈出一步 然后如此往复 如果你从右边不远处开始 梯度下降算法将会带你来到 这个右边的第二个局部最优处 如果从刚才的第一个点出发 你会得到这个局部最优解 但如果你的起始点偏移了一些 起始点的位置略有不同 你会得到一个 非常不同的局部最优解 这就是梯度下降算法的一个特点 我们会在之后继续探讨这个问题 好的 这是我们从图中得到的直观感受
### 梯度下降算法的定义
![梯度下降算法的定义](amWiki/images/001/01-Week1/4-Parameter Learning/4_梯度下降算法的定义.jpg)
看看这个图 这是梯度下降算法的定义 我们将会反复做这些 直到收敛 我们要更新参数 θj 方法是 用 θj 减去 α乘以这一部分  让我们来看看 这个公式有很多细节问题 我来详细讲解一下 首先 注意这个符号 := 我们使用 := 表示赋值 这是一个赋值运算符 具体地说 如果我写 a:= b 在计算机专业内 这意味着不管 a的值是什么 取 b的值 并将其赋给a 这意味着我们让 a等于b的值 这就是赋值 我也可以做 a:= a+1 这意味着 取出a值 并将其增加1 与此不同的是 如果我使用等号 = 并且写出a=b 那么这是一个判断为真的声明 如果我写 a=b 就是在断言 a的值是等于 b的值的 在左边这里 这是计算机运算 将一个值赋给 a 而在右边这里 这是声明 声明 a的值 与b的值相同 因此 我可以写 a:=a+1 这意味着 将 a的值再加上1 但我不会写 a=a+1 因为这本来就是错误的 a 和 a+1 永远不会是同一个值 这是这个定义的第一个部分 这里的α 是一个数字 被称为学习速率 什么是α呢? 在梯度下降算法中 它控制了 我们下山时会迈出多大的步子 因此如果 α值很大 那么相应的梯度下降过程中 我们会试图用大步子下山 如果α值很小 那么我们会迈着很小的小碎步下山 关于如何设置 α的值等内容 在之后的课程中 我会回到这里并且详细说明 最后 是公式的这一部分 这是一个微分项 我现在不想谈论它 但我会推导出这个微分项 并告诉你到底这要如何计算 你们中有人大概比较熟悉微积分 但即使你不熟悉微积分 也不用担心 我会告诉你 对这一项 你最后需要做什么 现在 在梯度下降算法中 还有一个更微妙的问题 在梯度下降中 我们要更新 θ0和θ1 当 j=0 和 j=1 时 会产生更新 所以你将更新 J θ0还有θ1 实现梯度下降算法的微妙之处是 在这个表达式中 如果你要更新这个等式 你需要同时更新 θ0和θ1 我的意思是在这个等式中 我们要这样更新 θ0:=θ0 - 一些东西 并更新 θ1:=θ1 - 一些东西 实现方法是 你应该计算公式右边的部分 通过那一部分计算出θ0和θ1的值 然后同时更新 θ0和θ1 让我进一步阐述这个过程 在梯度下降算法中 这是正确实现同时更新的方法 我要设 temp0等于这些 设temp1等于那些 所以首先计算出公式右边这一部分 然后将计算出的结果 一起存入 temp0和 temp1 之中 然后同时更新 θ0和θ1 因为这才是正确的实现方法 与此相反 下面是不正确的实现方法 因为它没有做到同步更新 在这种不正确的实现方法中 我们计算 temp0 然后我们更新θ0 然后我们计算 temp1 然后我们将 temp1 赋给θ1 右边的方法和左边的区别是 让我们看这里 就是这一步 如果这个时候你已经更新了θ0 那么你会使用 θ0的新的值来计算这个微分项 所以由于你已经在这个公式中使用了新的 θ0的值 那么这会产生一个与左边不同的 temp1的值 所以右边并不是正确地实现梯度下降的做法 我不打算解释为什么你需要同时更新 同时更新是梯度下降中的一种常用方法 我们之后会讲到 实际上同步更新是更自然的实现方法 当人们谈到梯度下降时 他们的意思就是同步更新 如果用非同步更新去实现算法 代码可能也会正确工作 但是右边的方法并不是人们所指的那个梯度下降算法 而是具有不同性质的其他算法 由于各种原因 这其中会表现出微小的差别 你应该做的是 在梯度下降中真正实现同时更新 这些就是梯度下降算法的梗概 在接下来的视频中 我们要进入这个微分项的细节之中 我已经写了出来但没有真正定义 如果你已经修过微积分课程 如果你熟悉偏导数和导数 这其实就是这个微分项 如果你不熟悉微积分 不用担心 即使你之前没有看过微积分 或者没有接触过偏导数 在接下来的视频中 你会得到一切你需要知道的 如何计算这个微分项的知识 下一个视频中 希望我们能够给出 实现梯度下降算法的所有知识
### 内嵌习题_理解θ0和θ1同步更新
![内嵌习题_理解θ0和θ1同步更新](amWiki/images/001/01-Week1/4-Parameter Learning/5_内嵌习题_理解θ0和θ1同步更新.jpg)
## English
### Gradient Descent Algorithm
![Gradient Descent Algorithm](amWiki/images/001/01-Week1/4-Parameter Learning/1_梯度下降算法.jpg)
We previously defined the cost function J. In this video, I want to tell you about an algorithm called gradient descent for minimizing the cost function J. It turns out gradient descent is a more general algorithm, and is used not only in linear regression. It's actually used all over the place in machine learning. And later in the class, we'll use gradient descent to minimize other functions as well, not just the cost function J for the linear regression. So in this video, we'll talk about gradient descent for minimizing some arbitrary function J and then in later videos, we'll take this algorithm and apply it specifically to the cost function J that we have defined for linear regression. So here's the problem setup. Going to assume that we have some function J(theta 0, theta 1) maybe it's the cost function from linear regression, maybe it's some other function we wanna minimize. And we want to come up with an algorithm for minimizing that as a function of J(theta 0, theta 1). Just as an aside it turns out that gradient descent actually applies to more general functions. So imagine, if you have a function that's a function of J, as theta 0, theta 1, theta 2, up to say some theta n, and you want to minimize theta 0. You minimize over theta 0 up to theta n of this J of theta 0 up to theta n. And it turns our gradient descent is an algorithm for solving this more general problem. But for the sake of brevity, for the sake of succinctness of notation, I'm just going to pretend I have only two parameters throughout the rest of this video. Here's the idea for gradient descent. What we're going to do is we're going to start off with some initial guesses for theta 0 and theta 1. Doesn't really matter what they are, but a common choice would be we set theta 0 to 0, and set theta 1 to 0, just initialize them to 0. What we're going to do in gradient descent is we'll keep changing theta 0 and theta 1 a little bit to try to reduce J(theta 0, theta 1), until hopefully, we wind at a minimum, or maybe at a local minimum.

###  How Gradient Descent Algorithm Works?
![How Gradient Descent Algorithm Works](amWiki/images/001/01-Week1/4-Parameter Learning/2_梯度下降法是如何工作的.jpg)
So let's see in pictures what gradient descent does. Let's say you're trying to minimize this function. So notice the axes, this is theta 0, theta 1 on the horizontal axes and J is the vertical axis and so the height of the surface shows J and we want to minimize this function. So we're going to start off with theta 0, theta 1 at some point. So imagine picking some value for theta 0, theta 1, and that corresponds to starting at some point on the surface of this function. So whatever value of theta 0, theta 1 gives you some point here. I did initialize them to 0, 0 but sometimes you initialize it to other values as well. Now, I want you to imagine that this figure shows a hole. Imagine this is like the landscape of some grassy park, with two hills like so, and I want us to imagine that you are physically standing at that point on the hill, on this little red hill in your park. In gradient descent, what we're going to do is we're going to spin 360 degrees around, just look all around us, and ask, if I were to take a little baby step in some direction, and I want to go downhill as quickly as possible, what direction do I take that little baby step in? If I wanna go down, so I wanna physically walk down this hill as rapidly as possible. Turns out, that if you're standing at that point on the hill, you look all around and you find that the best direction is to take a little step downhill is roughly that direction. Okay, and now you're at this new point on your hill. You're gonna, again, look all around and say what direction should I step in order to take a little baby step downhill? And if you do that and take another step, you take a step in that direction. And then you keep going. From this new point you look around, decide what direction would take you downhill most quickly. Take another step, another step, and so on until you converge to this local minimum down here. Gradient descent has an interesting property. This first time we ran gradient descent we were starting at this point over here, right? Started at that point over here.
### Different initialize value different local optimum
![Different initialize value different local optimum](amWiki/images/001/01-Week1/4-Parameter Learning/3_不同初始化值得到不同的局部最优解.jpg)
Now imagine we had initialized gradient descent just a couple steps to the right. Imagine we'd initialized gradient descent with that point on the upper right. If you were to repeat this process, so start from that point, look all around, take a little step in the direction of steepest descent, you would do that. Then look around, take another step, and so on. And if you started just a couple of steps to the right, gradient descent would've taken you to this second local optimum over on the right. So if you had started this first point, you would've wound up at this local optimum, but if you started just at a slightly different location, you would've wound up at a very different local optimum. And this is a property of gradient descent that we'll say a little bit more about later. So that's the intuition in pictures.
### Definition of the gradient descent algorithm
![Definition of the gradient descent algorithm](amWiki/images/001/01-Week1/4-Parameter Learning/4_梯度下降算法的定义.jpg)
Let's look at the math. This is the definition of the gradient descent algorithm. We're going to just repeatedly do this until convergence, we're going to update my parameter theta j by taking theta j and subtracting from it alpha times this term over here, okay? So let's see, there's lot of details in this equation so let me unpack some of it. First, this notation here, :=, gonna use := to denote assignment, so it's the assignment operator. So briefly, if I write a := b, what this means is, it means in a computer, this means take the value in b and use it overwrite whatever value is a. So this means set a to be equal to the value of b, which is assignment. And I can also do a := a + 1. This means take a and increase its value by one. Whereas in contrast, if I use the equal sign and I write a equals b, then this is a truth assertion.Okay? So if I write a equals b, then I'll asserting that the value of a equals to the value of b, right? So the left hand side, that's the computer operation, where we set the value of a to a new value. The right hand side, this is asserting, I'm just making a claim that the values of a and b are the same, and so whereas you can write a := a + 1, that means increment a by 1, hopefully I won't ever write a = a + 1 because that's just wrong. a and a + 1 can never be equal to the same values. Okay? So this is first part of the definition. This alpha here is a number that is called the learning rate.And what alpha does is it basically controls how big a step we take downhill with creating descent. So if alpha is very large, then that corresponds to a very aggressive gradient descent procedure where we're trying take huge steps downhill and if alpha is very small, then we're taking little, little baby steps downhill. And I'll come back and say more about this later, about how to set alpha and so on.And finally, this term here, that's a derivative term. I don't wanna talk about it right now, but I will derive this derivative term and tell you exactly what this is later, okay? And some of you will be more familiar with calculus than others, but even if you aren't familiar with calculus, don't worry about it. I'll tell you what you need to know about this term here.Now, there's one more subtlety about gradient descent which is in gradient descent we're going to update, you know, theta 0 and theta 1, right? So this update takes place for j = 0 and j = 1, so you're gonna update theta 0 and update theta 1. And the subtlety of how you implement gradient descent is for this expression, for this update equation, you want to simultaneously update theta 0 and theta 1. What I mean by that is that in this equation, we're gonna update theta 0 := theta 0 minus something, and update theta 1 := theta 1 minus something. And the way to implement is you should compute the right hand side, right? Compute that thing for theta 0 and theta 1 and then simultaneously, at the same time, update theta 0 and theta 1, okay? So let me say what I mean by that. This is a correct implementation of gradient descent meaning simultaneous update. So I'm gonna set temp0 equals that, set temp1 equals that so basic compute the right-hand sides, and then having computed the right-hand sides and stored them into variables temp0 and temp1, I'm gonna update theta 0 and theta 1 simultaneously because that's the correct implementation.In contrast, here's an incorrect implementation that does not do a simultaneous update. So in this incorrect implementation, we compute temp0, and then we update theta 0, and then we compute temp1, and then we update temp1.And the difference between the right hand side and the left hand side implementations is that If you look down here, you look at this step, if by this time you've already updated theta 0, then you would be using the new value of theta 0 to compute this derivative term. And so this gives you a different value of temp1, than the left-hand side, right? Because you've now plugged in the new value of theta 0 into this equation. And so, this on the right-hand side is not a correct implementation of gradient descent, okay? So I don't wanna say why you need to do the simultaneous updates. It turns out that the way gradient descent is usually implemented, which I'll say more about later, it actually turns out to be more natural to implement the simultaneous updates. And when people talk about gradient descent, they always mean simultaneous update. If you implement the non simultaneous update, it turns out it will probably work anyway. But this algorithm wasn't right. It's not what people refer to as gradient descent, and this is some other algorithm with different properties. And for various reasons this can behave in slightly stranger ways, and so what you should do is really implement the simultaneous update of gradient descent. So, that's the outline of the gradient descent algorithm. In the next video, we're going to go into the details of the derivative term, which I wrote up but didn't really define. And if you've taken a calculus class before and if you're familiar with partial derivatives and derivatives, it turns out that's exactly what that derivative term is, but in case you aren't familiar with calculus, don't worry about it. The next video will give you all the intuitions and will tell you everything you need to know to compute that derivative term, even if you haven't seen calculus, or even if you haven't seen partial derivatives before. And with that, with the next video, hopefully we'll be able to give you all the intuitions you need to apply gradient descent.
### Video Exam about simultaneous update
![Video Exam about simultaneous update](amWiki/images/001/01-Week1/4-Parameter Learning/5_内嵌习题_理解θ0和θ1同步更新.jpg)
