# 应用机器学习算法建议-正则化和高偏差【欠拟合】高方差【过拟合】
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/06-Week6/1-Advice for Applying Machine Learning/5-Regularization and Bias_Variance.mp4" type="video/mp4">
</video>
## 中文
### 回顾正则化线性回归
![回顾正则化线性回归](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/22-回顾正则化线性回归.jpg)  
现在你应该已经知道 算法正则化可以有效地防止过拟合 但正则化跟算法的偏差和方差 又有什么关系呢？ 在这段视频中 我想更深入地 探讨一下偏差和方差的问题 讨论一下两者之间 是如何相互影响的 以及和算法的正则化之间的相互关系 假如我们要对这样一个高阶多项式进行拟合 为了防止过拟合现象 我们要使用一个正则化项 因此我们试图通过这样一个正则化项 来让参数的值尽可能小 正则化项的求和范围照例取为 j 等于1到 m 而非 j 等于0到 m 然后我们来分析以下三种情形 第一种情形是正则化参数 λ 取一个比较大的值 比如 λ 的值取为10000甚至更大 在这种情况下 所有这些参数 θ1 θ2 θ3 等等 将被大大惩罚 其结果是 这些参数的值将近似等于0 并且假设模型 h(x) 的值将等于或者近似等于 θ0 因此我们最终得到的假设函数 应该是这个样子 近似是一条平滑的直线 因此这个假设处于高偏差 对数据集欠拟合(underfit) 因此一条水平直线 对这个数据集来讲不是一个好的假设 与之对应的另一种情况是 λ值很小 比如说 λ 的值等于0 在这种情况下 如果我们要拟合一个高阶多项式的话 那么我们通常会处于过拟合(overfitting)的情况 在拟合一个高阶多项式时 如果没有进行正则化 或者正则化程度很微小的话 我们通常会得到高方差和过拟合的结果 因为 λ 的值等于0相当于没有正则化项 因此会对假设过拟合 只有当我们取一个中间大小的 既不大也不小的 λ 值时 我们才会得到一组合理的 对数据刚好拟合的 θ 参数值 那么我们应该怎样自动地选择出一个最合适的正则化参数 λ 呢？
### 假设函数和非正则化训练集、验证集、测试集误差
![假设函数和非正则化训练集、验证集、测试集误差](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/23-假设函数和非正则化训练集、验证集、测试集误差.jpg)
重申一下 我们的模型和学习参数 以及最优化目标是这样的 让我们假设在使用正则化的情形中 定义 Jtrain(θ) 为另一种不同的形式 同样定义为最优化目标 但不使用正则化项 在先前的授课视频中 当我们没有使用正则化时 我们定义的Jtrain(θ) 就是代价函数J(θ) 但当我们使用正则化多出这个 λ 项时 我们就将训练集误差 也就是Jtrain 定义为 训练集数据预测误差的平方求和 或者说是训练集的平均误差平方和 但不考虑正则化项 与此类似 我们来定义交叉验证集误差和测试集误差 和之前一样定义为 对交叉验证集和测试集进行预测的平均误差平方和 总结一下 我们对于训练误差Jtrain Jcv Jtest的定义 都是平均误差平方和 或者准确地说 是训练集 验证集和测试集进行预测 在不使用正则化项时 平均误差平方和的一半
### 选取正则化参数进行交叉验证误差估算
![选取正则化参数进行交叉验证误差估算](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/24-选取正则化参数进行交叉验证误差估算.jpg)
下面就是我们自动选取正则化参数 λ 的方法 通常我的做法是 选取一系列我想要尝试的 λ 值 因此首先我可能考虑不使用正则化的情形 以及一系列我可能会试的值 比如说我可能从0.01 0.02 0.04开始 一直试下去 通常我会将步长设为2倍速度增长 直到一个比较大的值 在本例中以两倍步长递增的话 我们最终取值10.24 实际上我们取的是10 但已经非常接近了 因为小数点后的24对最终的结果不会有太大影响 因此 这样我就得到了12个不同的正则化参数 λ 对应的12个不同的模型 当然了 你也可以试小于0.01的值或者大于10的值 但在这里我就不讨论这些情况了 得到这12组模型后 接下来我们要做的事情是 选用第一个模型 也就是 λ 等于0 然后最小化我们的代价函数 J(θ) 这样我们就得到了某个参数向量 θ 与之前视频的做法类似 我使用θ上标(1) 来表示第一个参数向量θ 然后我再取第二个模型 λ 等于0.01的模型 最小化代价方差 当然现在 λ 等于0.01 那么会得到一个完全不同的参数向量 θ 用 θ(2)来表示 同理 接下来我会得到 θ(3) 对应于我的第三个模型 以此类推 一直到最后一个 λ 等于10或10.24的模型 对应 θ(12) 接下来我就可以用交叉验证集来评价这些假设和参数了 因此我可以从第一个模型开始 然后是第二个模型 对每一个不同的正则化参数 λ 进行拟合 然后用交叉验证集来评价每一个模型 也即测出每一个参数 θ 在交叉验证集上的平均误差平方和 然后我就选取这12个模型中交叉验证集误差最小的 那个模型作为最终选择 对于本例而言 假如说 最终我选择了 θ(5) 也就是五次多项式 因为此时的交叉验证集误差最小 做完这些 最后 如果我想看看该模型在测试集上的表现 我可以用经过学习得到的模型 θ(5) 来测出它对测试集的预测效果如何 再次重申 这里我们依然是用交叉验证集来拟合模型 这也是为什么我之前预留了一部分数据作为测试集的原因 这样我就可以用这部分测试集比较准确地估计出 我的参数向量 θ 对于新样本的泛化能力 这就是模型选择在选取正则化参数 λ 时的应用 在这段视频中我想讲的
### 正则化参数和高偏差高方差关系示意图
![正则化参数和高偏差高方差关系示意图](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/25-正则化参数和高偏差高方差关系示意图.jpg)
最后一个问题是 当我们改变正则化参数 λ 的值时 交叉验证集误差和训练集误差 会随之发生怎样的变化 我想提醒一下 我们最初的代价函数 J(θ) 但在这里我们把训练误差 定义为不包括正则化项 交叉验证集误差也定义为不包括正则化项 我要做的是绘制出 Jtrain和 Jcv 的曲线 表达的是随着我增大正则化项参数 λ 的值 看看我的假设在训练集上的表现如何变化 以及在交叉验证集上表现如何变化 就像我们之前看到的 如果 λ 的值很小 那也就是说我们几乎没有使用正则化 因此我们有很大可能处于过拟合 而如果 λ 的值取的很大的时候 也就是说取值在横坐标的右端 那么由于 λ 的值很大 我们很有可能处于高偏差的问题 所以 如果你画出 Jtrain 和 Jcv 的曲线 你就会发现 当 λ 的值取得很小时 对训练集的拟合相对较好 因为没有使用正则化 因此 对于 λ 值很小的情况正则化项可以忽略 你只需要对平方误差求最小值即可 所以当 λ 值很小时 你最终能得到一个值很小的Jtrain 而如果 λ 的值很大时你将处于高偏差问题 不能对训练集很好地拟合 因此你的误差值可能位于这个位置 因此 当 λ 增大时 训练集误差Jtrain的值 会趋于上升 因为 λ 的值比较大时对应着高偏差的问题 此时你连训练集都不能很好地拟合 反过来 当 λ 的值取得很小的时候 你的数据能随意地与高次多项式很好地拟合 而交叉验证集误差的曲线是这样的 在曲线的右端 当 λ 的值取得很大时 我们会处于欠拟合问题 因此这对应着偏差问题 那么此时交叉验证集误差将会很大 我写在这里 这是交叉验证集误差Jcv(θ) 由于高偏差的原因我们不能很好地拟合 我们的假设不能在交叉验证集上表现地比较好 而曲线的左端对应的是高方差问题 此时我们的 λ 值取得很小很小 因此我们会对数据过度拟合 所以由于过拟合的原因 交叉验证集误差也会很大 好的 这就是当我们改变正则化参数 λ 的值时 交叉验证集误差和训练集误差随之发生的变化 当然 在中间取的某个 λ 的值 表现得刚好合适 这种情况下表现最好 交叉验证集误差或者测试集误差都很小 当然由于我在这里画的图显得太卡通 也太理想化了 对于真实的数据 你得到的曲线可能比这看起来更凌乱 会有很多的噪声 对某个实际的数据集 你或多或少能看出像这样的一个趋势 通过绘出这条曲线 通过交叉验证集误差的变化趋势 你可以用自己选择出 或者编写程序自动得出能使交叉验证集误差最小的那个点 然后选出那个与之对应的参数 λ 的值 当我在尝试为学习算法选择正则化参数 λ 的时候 我通常都会画出像这样一个图 帮助我更好地理解各种情况 同时也帮助我确认 我选择的正则化参数值到底好不好 希望这节课的内容让你更深入地理解了正则化 以及它对学习算法的偏差和方差的影响 到目前为止你已经从不同角度认识了方差和偏差问题 在下一节视频中我要做的是 基于我们已经介绍过的所有这些概念 将它们结合起来 建立我们的诊断法 也称为学习曲线 这种方法通常被用来诊断一个学习算法 到底是处于偏差问题还是方差问题 还是两者都有
### 内置习题
![内置习题_理解高偏差【欠拟合】和高方差【过拟合】](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/26-内置习题_理解正则化参数和高偏差高方差关系1.jpg)  
![内置习题_理解高偏差【欠拟合】和高方差【过拟合】](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/27-内置习题_理解正则化参数和高偏差高方差关系2.jpg)  
## English
### Review linear regression regularization
![Review linear regression regularization](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/22-回顾正则化线性回归.jpg)  
You've seen how regularization can help prevent over-fitting. But how does it affect the bias and variances of a learning algorithm? In this video I'd like to go deeper into the issue of bias and variances and talk about how it interacts with and is affected by the regularization of your learning algorithm.Suppose we're fitting a high auto polynomial, like that showed here, but to prevent over fitting we need to use regularization, like that shown here. So we have this regularization term to try to keep the values of the prem to small. And as usual, the regularizations comes from J = 1 to m, rather than j = 0 to m. Let's consider three cases. The first is the case of the very large value of the regularization parameter lambda, such as if lambda were equal to 10,000. Some huge value.In this case, all of these parameters, theta 1, theta 2, theta 3, and so on would be heavily penalized and so we end up with most of these parameter values being closer to zero. And the hypothesis will be roughly h of x, just equal or approximately equal to theta zero. So we end up with a hypothesis that more or less looks like that, more or less a flat, constant straight line. And so this hypothesis has high bias and it badly under fits this data set, so the horizontal straight line is just not a very good model for this data set. At the other extreme is if we have a very small value of lambda, such as if lambda were equal to zero. In that case, given that we're fitting a high order polynomial, this is a usual over-fitting setting. In that case, given that we're fitting a high-order polynomial, basically, without regularization or with very minimal regularization, we end up with our usual high-variance, over fitting setting. This is basically if lambda is equal to zero, we're just fitting with our regularization, so that over fits the hypothesis. And it's only if we have some intermediate value of longer that is neither too large nor too small that we end up with parameters data that give us a reasonable fit to this data. So, how can we automatically choose a good value for the regularization parameter?
### Hypothesis Function and the unregularization training set, validation set and test set error
![Hypothesis Function and the unregularization training set, validation set and test set error](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/23-假设函数和非正则化训练集、验证集、测试集误差.jpg)
Just to reiterate, here's our model, and here's our learning algorithm's objective. For the setting where we're using regularization, let me define J train(theta) to be something different, to be the optimization objective, but without the regularization term. Previously, in an earlier video, when we were not using regularization I define J train of data to be the same as J of theta as the cause function but when we're using regularization when the six well under term we're going to define J train my training set to be just my sum of squared errors on the training set or my average squared error on the training set without taking into account that regularization. And similarly I'm then also going to define the cross validation sets error and to test that error as before to be the average sum of squared errors on the cross validation in the test sets so just to summarize my definitions of J train J CU and J test are just the average square there one half of the other square record on the training validation of the test set without the extra regularization term.
### Selection of regularization parameter for cross validation error estimate
![Selection of regularization parameter for cross validation error estimate](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/24-选取正则化参数进行交叉验证误差估算.jpg)
So, this is how we can automatically choose the regularization parameter lambda. So what I usually do is maybe have some range of values of lambda I want to try out. So I might be considering not using regularization or here are a few values I might try lambda considering lambda = 0.01, 0.02, 0.04, and so on. And I usually set these up in multiples of two, until some maybe larger value if I were to do these in multiples of 2 I'd end up with a 10.24. It's 10 exactly, but this is close enough. And the three to four decimal places won't effect your result that much. So, this gives me maybe 12 different models. And I'm trying to select a month corresponding to 12 different values of the regularization of the parameter lambda. And of course you can also go to values less than 0.01 or values larger than 10 but I've just truncated it here for convenience. Given the issue of these 12 models, what we can do is then the following, we can take this first model with lambda equals zero and minimize my cost function J of data and this will give me some parameter of active data. And similar to the earlier video, let me just denote this as theta super script one.And then I can take my second model with lambda set to 0.01 and minimize my cost function now using lambda equals 0.01 of course. To get some different parameter vector theta. Let me denote that theta(2). And for that I end up with theta(3). So if part for my third model. And so on until for my final model with lambda set to 10 or 10.24, I end up with this theta(12). Next, I can talk all of these hypotheses, all of these parameters and use my cross validation set to validate them so I can look at my first model, my second model, fit to these different values of the regularization parameter, and evaluate them with my cross validation set based in measure the average square error of each of these square vector parameters theta on my cross validation sets. And I would then pick whichever one of these 12 models gives me the lowest error on the trans validation set. And let's say, for the sake of this example, that I end up picking theta 5, the 5th order polynomial, because that has the lowest cause validation error. Having done that, finally what I would do if I wanted to report each test set error, is to take the parameter theta 5 that I've selected, and look at how well it does on my test set. So once again, here is as if we've fit this parameter, theta, to my cross-validation set, which is why I'm setting aside a separate test set that I'm going to use to get a better estimate of how well my parameter vector, theta, will generalize to previously unseen examples. So that's model selection applied to selecting the regularization parameter lambda.
### Regularization parameter and high bias variance diagram
![Regularization parameter and high bias variance diagram](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/25-正则化参数和高偏差高方差关系示意图.jpg)
The last thing I'd like to do in this video is get a better understanding of how cross validation and training error vary as we vary the regularization parameter lambda. And so just a reminder right, that was our original cost on j of theta. But for this purpose we're going to define training error without using a regularization parameter, and cross validation error without using the regularization parameter.And what I'd like to do is plot this Jtrain and plot this Jcv, meaning just how well does my hypothesis do on the training set and how does my hypothesis do when it cross validation sets. As I vary my regularization parameter lambda.So as we saw earlier if lambda is small then we're not using much regularization and we run a larger risk of over fitting whereas if lambda is large that is if we were on the right part of this horizontal axis then, with a large value of lambda, we run the higher risk of having a biased problem, so if you plot J train and J cv, what you find is that, for small values of lambda, you can fit the trading set relatively way cuz you're not regularizing. So, for small values of lambda, the regularization term basically goes away, and you're just minimizing pretty much just gray arrows. So when lambda is small, you end up with a small value for Jtrain, whereas if lambda is large, then you have a high bias problem, and you might not feel your training that well, so you end up the value up there. So Jtrain of theta will tend to increase when lambda increases, because a large value of lambda corresponds to high bias where you might not even fit your trainings that well, whereas a small value of lambda corresponds to, if you can really fit a very high degree polynomial to your data, let's say. After the cost validation error we end up with a figure like this,where over here on the right, if we have a large value of lambda, we may end up under fitting, and so this is the bias regime. And so the cross validation error will be high. Let me just leave all of that to this Jcv (theta) because so, with high bias, we won't be fitting, we won't be doing well in cross validation sets, whereas here on the left, this is the high variance regime, where we have two smaller value with longer, then we may be over fitting the data. And so by over fitting the data, then the cross validation error will also be high. And so, this is what the cross validation error and what the trading error may look like on a trading stance as we vary the regularization parameter lambda. And so once again, it will often be some intermediate value of lambda that is just right or that works best In terms of having a small cross validation error or a small test theta. And whereas the curves I've drawn here are somewhat cartoonish and somewhat idealized so on the real data set the curves you get may end up looking a little bit more messy and just a little bit more noisy then this. For some data sets you will really see these for sorts of trends and by looking at a plot of the hold-out cross validation error you can either manual, automatically try to select a point that minimizes the cross validation error and select the value of lambda corresponding to low cross validation error. When I'm trying to pick the regularization parameter lambda for learning algorithm, often I find that plotting a figure like this one shown here helps me understand better what's going on and helps me verify that I am indeed picking a good value for the regularization parameter monitor. So hopefully that gives you more insight into regularization and it's effects on the bias and variance of a learning algorithm. By now you've seen bias and variance from a lot of different perspectives. And what we like to do in the next video is take all the insights we've gone through and build on them to put together a diagnostic that's called learning curves, which is a tool that I often use to diagnose if the learning algorithm may be suffering from a bias problem or a variance problem, or a little bit of both.
### Exam_in the video
![Exam_Understand regularization parameter and high bias variance diagram](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/26-内置习题_理解正则化参数和高偏差高方差关系1.jpg)  
![Exam_Understand regularization parameter and high bias variance diagram](amWiki/images/001/06-Week6/1-Advice for Applying Machine Learning/27-内置习题_理解正则化参数和高偏差高方差关系2.jpg)  
