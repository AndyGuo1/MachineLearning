# 分类问题_【代价函数】高级优化
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/03-Week3/1-Logistic Regression/6-Advanced Optimization.mp4" type="video/mp4">
</video>
## 中文
### 回顾代价函数最小化算法-梯度下降
![回顾代价函数最小化算法-梯度下降](amWiki/images/001/03-Week3/1-Logistic Regression/29-回顾代价函数最小化算法-梯度下降.jpg)  
在上节课的视频中 用梯度下降的方法最小化 逻辑回归中代价函数 J(θ) 在这段视频中 教你们一些 高级优化算法和一些 高级的优化概念 利用这些方法 我们就能够 使通过梯度下降进行逻辑回归的速度 大大提高 而这也将使 算法更加适合解决 大型的机器学习问题 比如 我们有数目庞大的特征量 现在我们换个角度 来看什么是梯度下降 我们有个代价函数 J 而我们想要使其最小化  那么我们需要做的是 我们需要 编写代码 当输入参数 θ 时 它们会计算出两样东西  J(θ) 以及 J等于 0 1直到 n 时的 偏导数项 假设我们已经完成了 可以实现这两件事的代码 那么梯度下降所做的就是 反复执行这些更新 生成了这个叫做 data 的对象 是吧？ 所以给出我们 用于计算这些的偏导数的代码 梯度下降法就把它插入 到这里 从而来更新参数 θ 因此另一种考虑 梯度下降的思路是 我们需要写出代码 来计算 J(θ) 这些偏导数 然后 把这些插入到梯度下降中 然后它就可以为我们最小化这个函数 对于梯度下降来说 我认为 从技术上讲 你实际并不需要编写代码 来计算代价函数 J(θ) 你只需要编写代码来计算导数项 但是 如果你希望 代码还要能够监控 这些 J(θ) 的收敛性 那么我们就 需要自己编写代码 来计算 代价函数和偏导数项所以 在写完能够 计算这两者的代码之后 我们就可以使用梯度下降
### 代价函数高级优化算法及优缺点
![代价函数高级优化算法及优缺点](amWiki/images/001/03-Week3/1-Logistic Regression/30-代价函数高级优化算法及优缺点.jpg)
但梯度下降并不是我们可以使用的唯一算法 还有其他一些算法 更高级 更复杂 如果我们能用 这些方法来计算 这两个项的话 那么这些算法 就是为我们优化 代价函数的不同方法 共轭梯度法 BFGS (变尺度法) 和  L-BFGS (限制变尺度法) 就是其中  一些更高级的优化算法 它们需要有一种方法来计算 J(θ) 以及需要一种方法 计算导数项 然后使用比梯度下降更复杂 的算法来最小化代价函数 这三种算法的具体细节 超出了本门课程的范畴 实际上你最后通常会 花费很多天 或几周时间研究这些算法 你可以专门学一门课来提高数值计算能力 不过让我来告诉你他们的一些特性这三种算法有许多优点 一个是 使用这其中任何一个算法 你通常 不需要手动选择学习率 α 所以对于 这些算法的一种思路是 给出 计算导数项和代价函数的方法 你可以认为算法有一个智能的内部循环 而且 事实上 他们确实有一个智能的内部循环 称为线性搜索(line search)算法 它可以自动 尝试不同的 学习速率 α 并自动 选择一个好的学习速率 α 因此它甚至可以 为每次迭代选择不同的学习速率 那么你就不需要自己选择这些算法实际上在做 更复杂的事情 而不仅仅是 选择一个好的学习速率 所以它们往往最终 收敛得远远快于梯度下降这些算法实际上在做 更复杂的事情 不仅仅是 选择一个好的学习速率 所以它们往往最终 比梯度下降收敛得快多了 不过 关于它们到底做什么的详细讨论 已经超过了本门课程的范围 实际上 我过去 使用这些算法 已经很长一段时间了 也许超过 十年了 使用得相当频繁  而直到几年前 我才真正 搞清楚 共轭梯度法 BFGS 和 L-BFGS的细节 因此 实际上完全有可能 成功使用这些算法 并应用于许多不同的学习 问题 而不需要真正理解 这些算法的内环间在做什么 如果说这些算法有缺点的话 那么我想说主要 缺点是它们比 梯度下降法复杂多了 特别是你最好 不要使用 L-BGFS BFGS这些算法 共轭梯度 L-BGFS BFGS 除非你是数值计算方面的专家实际上 我不会建议你们编写 自己的代码来计算 数据的平方根或者 计算逆矩阵 因为对于这些算法我 还是会建议你直接使用一个软件库 所以 要求一个平方根 我们所能做的 就是调用一些 别人已经 写好用来计算数字平方根的函数 幸运的是 有 Octave 和 与它密切相关的 MATLAB 语言 我们将会用到它们 Octave 有一个非常 理想的库用于实现这些先进的优化算法 所以 如果你直接调用 它自带的库 你就能得到不错的结果
### 举例说明代价函数高级优化算法-fminun函数
![举例说明代价函数高级优化算法-fminun函数](amWiki/images/001/03-Week3/1-Logistic Regression/31-举例说明代价函数高级优化算法-fminun函数.jpg)
我必须指出 这些算法 实现得好或不好是有区别的 因此 如果你正在你的 机器学习程序中使用一种不同的语言 比如如果你正在使用 C C + + Java 等等 你 可能会想尝试一些 不同的库 以确保你找到一个 能很好实现这些算法的库 因为 在 L-BFGS 或者等高线梯度的 实现上 表现得好与不太好 是有差别的 因此现在让我们来说明 如何使用这些算法 我打算举一个例子 比方说 你有一个 含两个参数的问题 这两个参数是 θ0 和 θ1 那么你的成本函数 J(θ)等于 θ1 减去5的平方 再加上 θ2 减5的平方 因此 通过这个代价函数 你可以得到 θ1 和 θ2 的值 如果你将 J(θ) 最小化的话 那么它的最小值 将是 θ1 等于5 θ2 等于5 我知道你们当中 有些人比别人微积分更好 但是你应该知道代价函数 J 的导数 推出来就是这两个表达式 我已经写在这儿了 那么你就可以应用 高级优化算法里的一个 来最小化代价函数 J 所以 如果我们 不知道最小值 是5 5 但你想要 代价函数找到这个最小值 是用比如 梯度下降这些算法 但最好是用 比它更高级的算法 你要做的就是运行一个 像这样的 Octave 函数 那么我们 运行一个函数 比如 costFunction 这个函数的作用就是 它会返回两个值 第一个是 jVal 它是我们计算的代价函数 J 所以说 jVal 等于 theta(1) 减5的平方加 theta(2) 减5的平方 这样就计算出这个代价函数函数返回的第二个值是 梯度值 梯度值应该是 一个2×1的向量梯度向量的两个元素 对应 这里的两个偏导数项运行这个 costFunction 函数后你就可以调用高级的优化函数这个函数叫 fminunc 它表示 Octave 里无约束最小化函数 调用它的方式如下 你要设置几个 options 这个 options 变量 作为一个数据结构可以存储你想要的 options 所以 GradObj 和 On 这里设置梯度目标参数为打开(on) 这意味着你现在确实要给这个算法提供一个梯度 然后设置最大 迭代次数 比方说 100 我们给出一个 θ 的猜测初始值 它是一个2×1的向量 那么这个命令就调用 fminunc 这个@符号表示 指向我们刚刚定义的costFunction 函数的指针 如果你调用它 它就会 使用众多高级优化算法中的一个 当然你也可以把它当成梯度下降 只不过它能自动选择 学习速率α 你不需要自己来做 然后它会尝试 使用这些高级的优化算法 就像加强版的梯度下降法 为你找到最佳的 θ 值 让我告诉你它在 Octave 里什么样所以我写了这个关于theta的 的 costFunction 函数 跟前面幻灯片中一样 它计算出代价函数 jval 以及梯度 gradient gradient 有两个元素 是代价函数对于 theta(1) 和 theta(2) 这两个参数的 偏导数现在 让我们切换到Octave窗口 我把刚刚的命令敲进去 options = optimset 这是 在我的优化算法的 options上设置参数 的记号 这样就是100 次迭代 我现在要给我的算法提供梯度值设置 theta 的初始值是一个2×1的零向量 这是我猜测的 theta 初始值 现在我就可以写出三个返回值[optTheta, functionVal, exitFlag] 等于指向代价函数的指针 @costFunction 我猜测的初始值 initialTheta 还有options 如果我敲回车 这个就会运行优化算法它很快返回值 这个格式很有意思 因为我的代码是被缠住了 所以这个有点意思 完全是因为我的命令行被绕住了 不过这里只是 数字上的一些问题 把它看成是加强版梯度下降 它们找到 theta 的最优值 是 theta(1) 为5 theta(2) 也为5 这正是我们希望的 functionVal 的值 实际上是10的-30次幂 所以 这基本上就是0 这也是我们所希望的 exitFlag为1 这说明它的状态 是已经收敛了的 你也可以运行  help fminunc 命令 去查阅相关资料 以理解 exitFlag 的作用 exitFlag可以让你确定该算法是否已经收敛 这就是在 Octave 里运行这些算法的过程 哦对了 这里我得指出 用 Octave 运行的时候 向量θ的值 θ的参数向量 必须是 d 维的 d 大于等于2 所以 θ 仅仅是一个实数 因此如果它不是 一个至少二维的向量 或高于二维的向量 fminunc 就可能无法运算 因此如果你有一个 一维的函数需要优化 一维的函数需要优化 你可以查找 Octave 里 fminuc 函数的资料 来得到更多的细节 来得到更多的细节 这就是我们如何优化 一个例子的过程 这是一个 简单的二次代价函数
### 代价函数高级优化算法-fminun函数向量化
![代价函数高级优化算法-fminun函数向量化](amWiki/images/001/03-Week3/1-Logistic Regression/32-代价函数高级优化算法-fminun函数向量化.jpg)
我们如果把它应用到逻辑回归中呢 在逻辑回归中 我们有 一个参数向量 theta 我要混合使用 Octave 记号和数学符号 我希望这个写法很明确 我们的参数 theta 由 θ0 到 θn 组成 由 θ0 到 θn 组成 因为在 Octave 的标号中向量的标号是从1开始的 在 Octave 里 θ0实际上 写成 theta(1) 因此用 theta(1) 表示第一个参数 θ0 然后有 theta(2) 接下来写到 theta(n+1) 对吧 这是因为 Octave 的记号 是向量从1开始的 而不是从0开始 因此 我们需要 做的是写一个 costFunction 函数 它为 逻辑回归求得代价函数 具体点说 costFunction 函数 需要返回 jVal 值 因此需要一些代码 来计算 J(θ) 我们也需要给出梯度值 gradient 那么 gradient(1) 对应用来计算代价函数 关于 θ0 的偏导数 接下去关于 θ1 的偏导数 依此类推 再次强调 这是 gradient(1) gradient(2) 等等 而不是gradient(0) gradient(1) 因为 Octave 的标号 是从1开始 而不是从0开始的我希望你们从这个幻灯片中 学到的主要内容是 你所要做的是 写一个函数 它能返回代价函数值 以及梯度值 因此要把这个 应用到逻辑回归 或者甚至线性回归中 你也可以把这些优化算法用于线性回归 你需要做的就是输入 合适的代码来计算 这里的这些东西 现在你已经知道如何使用这些高级的优化算法 有了这些算法  你就可以使用一个 复杂的优化库 它让算法使用起来更模糊一点 more opaque and so 因此也许稍微有点难调试 不过由于这些算法的运行速度 通常远远超过梯度下降 因此当我有一个很大的 机器学习问题时 我会选择这些高级算法 而不是梯度下降 有了这些概念 你就应该能将逻辑回归 和线性回归应用于 更大的问题中 这就是高级优化的概念 在下一个视频 也就是逻辑回归这一部分的最后一个视频中 我想要告诉你如何 修改你已经知道的逻辑回归算法 然后使它在多类别分类问题中 也能正常运行
### 内置习题
![内置习题_代价函数高级优化算法](amWiki/images/001/03-Week3/1-Logistic Regression/33-内置习题_代价函数高级优化算法.jpg)
## English
### Review Cost Funciton minimize algorithms - Gradient Descent
![Review Cost Funciton minimize algorithms - Gradient Descent](amWiki/images/001/03-Week3/1-Logistic Regression/29-回顾代价函数最小化算法-梯度下降.jpg)  
In the last video, we talked about gradient descent for minimizing the cost function J of theta for logistic regression. In this video, I'd like to tell you about some advanced optimization algorithms and some advanced optimization concepts.
Using some of these ideas, we'll be able to get logistic regression to run much more quickly than it's possible with gradient descent. And this will also let the algorithms scale much better to very large machine learning problems, such as if we had a very large number of features. Here's an alternative view of what gradient descent is doing. We have some cost function J and we want to minimize it. So what we need to is, we need to write code that can take as input the parameters theta and they can compute two things: J of theta and these partial derivative terms for, you know, J equals 0, 1 up to N. Given code that can do these two things, what gradient descent does is it repeatedly performs the following update. Right? So given the code that we wrote to compute these partial derivatives, gradient descent plugs in here and uses that to update our parameters theta.So another way of thinking about gradient descent is that we need to supply code to compute J of theta and these derivatives, and then these get plugged into gradient descents, which can then try to minimize the function for us. For gradient descent, I guess technically you don't actually need code to compute the cost function J of theta. You only need code to compute the derivative terms. But if you think of your code as also monitoring convergence of some such, we'll just think of ourselves as providing code to compute both the cost function and the derivative terms.So, having written code to compute these two things, one algorithm we can use is gradient descent.
### Advanced Optimization of Cost Function and Advantages or Disadvantage
![Advanced Optimization of Cost Function and Advantages or Disadvantage](amWiki/images/001/03-Week3/1-Logistic Regression/30-代价函数高级优化算法及优缺点.jpg)
But gradient descent isn't the only algorithm we can use. And there are other algorithms, more advanced, more sophisticated ones, that, if we only provide them a way to compute these two things, then these are different approaches to optimize the cost function for us. So conjugate gradient BFGS and L-BFGS are examples of more sophisticated optimization algorithms that need a way to compute J of theta, and need a way to compute the derivatives, and can then use more sophisticated strategies than gradient descent to minimize the cost function.The details of exactly what these three algorithms is well beyond the scope of this course. And in fact you often end up spending, you know, many days, or a small number of weeks studying these algorithms. If you take a class and advance the numerical computing.But let me just tell you about some of their properties.These three algorithms have a number of advantages. One is that, with any of this algorithms you usually do not need to manually pick the learning rate alpha.So one way to think of these algorithms is that given is the way to compute the derivative and a cost function. You can think of these algorithms as having a clever inter-loop. And, in fact, they have a clever inter-loop called a line search algorithm that automatically tries out different values for the learning rate alpha and automatically picks a good learning rate alpha so that it can even pick a different learning rate for every iteration. And so then you don't need to choose it yourself.
These algorithms actually do more sophisticated things than just pick a good learning rate, and so they often end up converging much faster than gradient descent.These algorithms actually do more sophisticated things than just pick a good learning rate, and so they often end up converging much faster than gradient descent, but detailed discussion of exactly what they do is beyond the scope of this course.In fact, I actually used to have used these algorithms for a long time, like maybe over a decade, quite frequently, and it was only, you know, a few years ago that I actually figured out for myself the details of what conjugate gradient, BFGS and O-BFGS do. So it is actually entirely possible to use these algorithms successfully and apply to lots of different learning problems without actually understanding the inter-loop of what these algorithms do.If these algorithms have a disadvantage, I'd say that the main disadvantage is that they're quite a lot more complex than gradient descent. And in particular, you probably should not implement these algorithms - conjugate gradient, L-BGFS, BFGS - yourself unless you're an expert in numerical computing.Instead, just as I wouldn't recommend that you write your own code to compute square roots of numbers or to compute inverses of matrices, for these algorithms also what I would recommend you do is just use a software library. So, you know, to take a square root what all of us do is use some function that someone else has written to compute the square roots of our numbers.And fortunately, Octave and the closely related language MATLAB - we'll be using that - Octave has a very good. Has a pretty reasonable library implementing some of these advanced optimization algorithms. And so if you just use the built-in library, you know, you get pretty good results.
### Example_Advanced Optimization of Cost Function-fminun
![Example_Advanced Optimization of Cost Function-fminun](amWiki/images/001/03-Week3/1-Logistic Regression/31-举例说明代价函数高级优化算法-fminun函数.jpg)
I should say that there is a difference between good and bad implementations of these algorithms. And so, if you're using a different language for your machine learning application, if you're using C, C++, Java, and so on, you might want to try out a couple of different libraries to make sure that you find a good library for implementing these algorithms. Because there is a difference in performance between a good implementation of, you know, contour gradient or LPFGS versus less good implementation of contour gradient or LPFGS.So now let's explain how to use these algorithms, I'm going to do so with an example.Let's say that you have a problem with two parameters equals theta zero and theta one. And let's say your cost function is J of theta equals theta one minus five squared, plus theta two minus five squared.So with this cost function. You know the value for theta 1 and theta 2. If you want to minimize J of theta as a function of theta. The value that minimizes it is going to be theta 1 equals 5, theta 2 equals equals five.Now, again, I know some of you know more calculus than others, but the derivatives of the cost function J turn out to be these two expressions. I've done the calculus.So if you want to apply one of the advanced optimization algorithms to minimize cost function J. So, you know, if we didn't know the minimum was at 5, 5, but if you want to have a cost function 5 the minimum numerically using something like gradient descent but preferably more advanced than gradient descent, what you would do is implement an octave function like this, so we implement a cost function,cost function theta function like that,and what this does is that it returns two arguments, the first J-val, is how we would compute the cost function J. And so this says J-val equals, you know, theta one minus five squared plus theta two minus five squared. So it's just computing this cost function over here.And the second argument that this function returns is gradient. So gradient is going to be a two by one vector,and the two elements of the gradient vector correspond to the two partial derivative terms over here.
Having implemented this cost function,you would, you can then call the advanced optimization function called the fminunc - it stands for function minimization unconstrained in Octave -and the way you call this is as follows. You set a few options. This is a options as a data structure that stores the options you want. So grant up on, this sets the gradient objective parameter to on. It just means you are indeed going to provide a gradient to this algorithm. I'm going to set the maximum number of iterations to, let's say, one hundred. We're going give it an initial guess for theta. There's a 2 by 1 vector. And then this command calls fminunc. This at symbol presents a pointer to the cost function that we just defined up there. And if you call this, this will compute, you know, will use one of the more advanced optimization algorithms. And if you want to think it as just like gradient descent. But automatically choosing the learning rate alpha for so you don't have to do so yourself. But it will then attempt to use the sort of advanced optimization algorithms. Like gradient descent on steroids. To try to find the optimal value of theta for you. Let me actually show you what this looks like in Octave.So I've written this cost function of theta function exactly as we had it on the previous line. It computes J-val which is the cost function. And it computes the gradient with the two elements being the partial derivatives of the cost function with respect to, you know, the two parameters, theta one and theta two.Now let's switch to my Octave window. I'm gonna type in those commands I had just now. So, options equals optimset. This is the notation for setting my parameters on my options, for my optimization algorithm. Grant option on, maxIter, 100 so that says 100 iterations, and I am going to provide the gradient to my algorithm.Let's say initial theta equals zero's two by one. So that's my initial guess for theta.And now I have of theta,function val exit flag equals fminunc constraint.A pointer to the cost function.and provide my initial guess.And the options like so. And if I hit enter this will run the optimization algorithm.And it returns pretty quickly. This funny formatting that's because my line, you know, my code wrapped around. So, this funny thing is just because my command line had wrapped around. But what this says is that numerically renders, you know, think of it as gradient descent on steroids, they found the optimal value of a theta is theta 1 equals 5, theta 2 equals 5, exactly as we're hoping for. The function value at the optimum is essentially 10 to the minus 30. So that's essentially zero, which is also what we're hoping for. And the exit flag is 1, and this shows what the convergence status of this. And if you want you can do help fminunc to read the documentation for how to interpret the exit flag. But the exit flag let's you verify whether or not this algorithm thing has converged.So that's how you run these algorithms in Octave.I should mention, by the way, that for the Octave implementation, this value of theta, your parameter vector of theta, must be in rd for d greater than or equal to 2. So if theta is just a real number. So, if it is not at least a two-dimensional vector or some higher than two-dimensional vector, this fminunc may not work, so and if in case you have a one-dimensional function that you use to optimize, you can look in the octave documentation for fminunc for additional details.So, that's how we optimize our trial example of this simple quick driving cost function.
### Example_Advanced Optimization of Cost Function-fminun Vetorization
![Example_Advanced Optimization of Cost Function-fminun Vetorization](amWiki/images/001/03-Week3/1-Logistic Regression/32-代价函数高级优化算法-fminun函数向量化.jpg)
However, we apply this to let's just say progression.
In logistic regression we have a parameter vector theta, and I'm going to use a mix of octave notation and sort of math notation. But I hope this explanation will be clear, but our parameter vector theta comprises these parameters theta 0 through theta n because octave indexes,vectors using indexing from 1, you know, theta 0 is actually written theta 1 in octave, theta 1 is gonna be written. So, if theta 2 in octave and that's gonna be a written theta n+1, right? And that's because Octave indexes is vectors starting from index of 1 and so the index of 0.So what we need to do then is write a cost function that captures the cost function for logistic regression. Concretely, the cost function needs to return J-val, which is, you know, J-val as you need some codes to compute J of theta and we also need to give it the gradient. So, gradient 1 is going to be some code to compute the partial derivative in respect to theta 0, the next partial derivative respect to theta 1 and so on. Once again, this is gradient 1, gradient 2 and so on, rather than gradient 0, gradient 1 because octave indexes is vectors starting from one rather than from zero.But the main concept I hope you take away from this slide is, that what you need to do, is write a function that returns the cost function and returns the gradient.And so in order to apply this to logistic regression or even to linear regression, if you want to use these optimization algorithms for linear regression.What you need to do is plug in the appropriate code to compute these things over here.So, now you know how to use these advanced optimization algorithms.Because, using, because for these algorithms, you're using a sophisticated optimization library, it makes the just a little bit more opaque and so just maybe a little bit harder to debug. But because these algorithms often run much faster than gradient descent, often quite typically whenever I have a large machine learning problem, I will use these algorithms instead of using gradient descent.
And with these ideas, hopefully, you'll be able to get logistic progression and also linear regression to work on much larger problems. So, that's it for advanced optimization concepts.And in the next and final video on Logistic Regression, I want to tell you how to take the logistic regression algorithm that you already know about and make it work also on multi-class classification problems.
### Exam_in the video
![Exam_Advanced Optimization of Cost Function](amWiki/images/001/03-Week3/1-Logistic Regression/33-内置习题_代价函数高级优化算法.jpg)
