# 分类问题_化简代价函数和梯度下降算法
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/03-Week3/1-Logistic Regression/5-Simplified Cost Function and Gradient Descent.mp4" type="video/mp4">
</video>
## 中文
### 分类问题_化简代价函数分析
![分类问题_化简代价函数分析](amWiki/images/001/03-Week3/1-Logistic Regression/22-分类问题_化简代价函数分析.jpg)  
在这个视频中，我们会找到一种比我们目前使用的更简单的方法来写成本函数。我们还将考虑如何应用梯度下降来适应逻辑回归的参数。因此，在这个视频的最后，你知道如何实现一个完整的逻辑回归的工作版本。这是逻辑回归的成本函数。我们的总成本函数是1 / m乘以对各种标签的不同预测成本的交易组合的总和。这是我们之前算过的一个例子的成本。我只是想提醒你们，对于我们训练集的分类问题，事实上，甚至举个例子，我们的训练集y总是等于0或1，对吧?这是y的数学定义的一部分。因为y不是0就是1，我们可以用更简单的方法来写出这个成本函数。特别地，不是把这个成本函数写在两个单独的情况下，所以y等于1,y等于0。
### 分类问题_代价函数简化形式
![分类问题_代价函数简化形式](amWiki/images/001/03-Week3/1-Logistic Regression/23-分类问题_代价函数简化形式.jpg)  
我将给你们展示一种方法，把这两条线压缩成一个方程。这样就可以更方便地写出成本函数和推导梯度下降。具体地说，我们可以写出如下的成本函数。我们说，H(x)，y的成本。我把这个写成- y乘以log h(x)-(1 - y)乘以log(1 - h(x))。我一会儿会给你们看这个表达式，不，这个方程，是等价的，或者更紧凑的方式，写出我们在这上面的成本函数的定义。我们来看看为什么会这样。我们知道只有两种可能的情况。Y一定是0或者1。假设Y等于1。如果y等于1，那么这个方程就等于，如果y等于1，那么这个就等于1。1 - y等于0，对吧。如果y = 1，那么1 - y = 1 - 1，因此是0。所以第二项乘以0就消去了。我们只剩下第一项，也就是y乘以log y乘以log(h(x))Y等于1，所以它等于- log h(x)。这个方程就是y = 1时的方程。另一种情况是y = 0。如果是这样的话，那么cos函数的写法就是，如果y等于0，那么这一项就等于0。而1 - y，如果y = 0，等于1， 是因为1-y等于1-0=1.因此，成本函数简化为最后一项，对吧?因为这里的第一项乘以零，所以它就消失了，所以它只剩下最后一项，也就是- log(1 - h(x))。你可以证明这一项就是y = 0时的情况。因此，这表明，对于成本的定义是一种更紧凑的方式，将这些表达式，y = 1和y = 0，以一种更方便的形式，只用一行来写。因此，我们可以把逻辑回归的所有成本函数写下来。它是这些成本函数之和的1 / m。代入我们之前算出的成本的定义，最后得到这个。我们把负号放在外面。为什么我们选择这个特殊的函数，它看起来可能是我们可以选择的其他成本函数。虽然我没有时间在本课程中详细讨论这个，但这个成本函数可以用最大似然估计的原则来推导。这是一个关于如何有效地为不同的模型找到参数数据的统计方法。它也有一个很好的性质，它是凸的。所以这是一个成本函数基本上每个人都用在符合逻辑回归模型的时候。如果你不明白我刚才说的那些术语，如果你不知道最大可能估计的原则是什么，不要担心。但这仅仅是一个比我在这门课上有时间进入的更深层的理由和理由。考虑到这个成本函数，为了符合参数，我们要做的是试着求出θ，使Jθ最小化。所以如果我们试着最小化这个，这会给我们一些参数θ。最后，如果我们有一个新的例子有一些特征x，那么我们就可以把我们的训练集和输出我们的预测放在一起。为了提醒你们，我的假设的输出是y等于1的概率。给定输入x和θ的参数。但是，你可以把这看成是我的假设，估计y等于1的概率。
### 分类问题_梯度下降同步更新
![分类问题_梯度下降同步更新](amWiki/images/001/03-Week3/1-Logistic Regression/24-分类问题_梯度下降同步更新.jpg)  
所以剩下要做的就是算出如何把J的θ最小化作为θ的函数，这样我们就可以把参数和我们的训练集结合起来了，我们要最小化成本函数的方法是使用梯度下降法。这是我们的成本函数，如果我们想把它最小化为θ的函数，这里是我们常用的梯度下降模板，我们反复更新每个参数，把它更新为它本身减去学习射线α乘以这个导数项。如果你知道一些微积分，你可以用这个术语来计算导数，看看你能不能把它简化成我得到的答案。但即使你不知道微积分也不用担心。
### 梯度下降算法在逻辑回归和线性回归中表示形式一致【假设函数不一致】
![梯度下降算法在逻辑回归和线性回归中表示形式一致【假设函数不一致】](amWiki/images/001/03-Week3/1-Logistic Regression/25-梯度下降算法在逻辑回归和线性回归中表示形式一致【假设函数不一致】.jpg)  
如果你真的计算这个，你得到的是这个方程，写在这里。它的和等于1到m的误差乘以xij。如果你求这个偏导数的项然后把它代入这里，我们可以写出我们的梯度下降算法如下。我所做的就是对之前的幻灯片做了一个导数项然后代入它。如果你有n个特征，你会有一个参数向量θ，它的参数是θ(0)θ1θ2，到θn。您将使用这个更新同时更新所有的θ值。现在，如果你把这个更新规则和我们正在做的线性回归做比较。我所做的就是对之前的幻灯片做了一个导数项然后代入它。如果你有n个特征，你会有一个参数向量θ，它的参数是θ(0)θ1θ2，到θn。您将使用这个更新同时更新所有的θ值。现在，如果你把这个更新规则和我们正在做的线性回归做比较。你可能会惊讶地发现，这个方程和线性回归是一样的。事实上，如果你看前面的视频，看一下更新规则，线性回归的梯度下降规则。它看起来和我在蓝盒子里画的完全一样。线性回归和逻辑回归是不同的算法吗?好，这是通过观察逻辑回归来解决的，已经改变的是这个假设的定义已经改变了。对于线性回归，我们有h(x)等于θ的转置，现在h(x)的定义已经改变。现在是1 / 1加上e的负的转置x。所以即使更新规则看起来是完全一样的，因为假设的定义已经改变了，这实际上和线性回归的梯度下降是不一样的。在早期的视频中，当我们讨论线性回归的梯度下降时，我们讨论了如何监控梯度下降以确保它是收敛的。我通常用同样的方法来进行逻辑回归，也就是监控梯度下降，以确保正确收敛。希望你们能想出如何运用这种技巧来回归逻辑回归。当用梯度下降实现逻辑回归时，我们有所有这些不同的参数值，θ0到θn，我们需要用这个表达式来更新。我们可以做的一件事是有一个for循环。对于i等于0到n，或者i等于1到n + 1。因此依次更新这些参数值。但是当然，我们不会使用for循环，理想情况下，我们也会使用向量提升实现。所以一个向量的实现可以更新所有这些m加上一个参数一下子。为了检查你自己的理解，你可能会发现，如果你能弄清楚如何用这个算法来实现向量的实现。现在你知道如何实现逻辑回归的梯度下降。我们之前讨论过的最后一个观点是线性回归，即特征缩放。我们看到特性扩展可以帮助梯度下降更快地收敛于线性回归。特征标度的概念也适用于逻辑回归的梯度下降。然而，我们有不同规模的特性，然后应用特性扩展可以使降级速度更快地进行逻辑回归。这就是，你现在知道如何实现逻辑回归，这是一个非常强大的，可能是世界上最常用的分类算法。现在你知道我们如何让它为你自己工作了。
### 内置习题
![内置习题_逻辑回归模型中代价函数以及梯度下降函数化简形式](amWiki/images/001/03-Week3/1-Logistic Regression/26-内置习题_逻辑回归模型中代价函数以及梯度下降函数化简形式.jpg)
![内置习题_逻辑回归模型中参数theta向量化](amWiki/images/001/03-Week3/1-Logistic Regression/27-内置习题_逻辑回归模型中参数theta向量化.jpg)
## English
### Classification_Simplified Cost Function Analysis
![Classification_Simplified Cost Function Analysis](amWiki/images/001/03-Week3/1-Logistic Regression/22-分类问题_化简代价函数分析.jpg)  
In this video, we'll figure out a slightly simpler way to write the cost function than we have been using so far. And we'll also figure out how to apply gradient descent to fit the parameters of logistic regression. So, by the end of this, video you know how to implement a fully working version of logistic regression.Here's our cost function for logistic regression. Our overall cost function is 1 over m times the sum over the trading set of the cost of making different predictions on the different examples of labels y i. And this is the cost of a single example that we worked out earlier. And just want to remind you that for classification problems in our training sets, and in fact even for examples, now that our training set y is always equal to zero or one, right? That's sort of part of the mathematical definition of y.Because y is either zero or one, we'll be able to come up with a simpler way to write this cost function. And in particular, rather than writing out this cost function on two separate lines with two separate cases, so y equals one and y equals zero.
### Classification_Simplified Cost Function
![Classification_Simplified Cost Function](amWiki/images/001/03-Week3/1-Logistic Regression/23-分类问题_代价函数简化形式.jpg)
I'm going to show you a way to take these two lines and compress them into one equation. And this would make it more convenient to write out a cost function and derive gradient descent. Concretely, we can write out the cost function as follows. We say that cost of H(x), y. I'm gonna write this as -y times log h(x)- (1-y) times log (1-h(x)). And I'll show you in a second that this expression, no, this equation, is an equivalent way, or more compact way, of writing out this definition of the cost function that we have up here. Let's see why that's the case.We know that there are only two possible cases. Y must be zero or one. So let's suppose Y equals one.If y is equal to 1, than this equation is saying that the cost is equal to, well if y is equal to 1, then this thing here is equal to 1. And 1 minus y is going to be equal to 0, right. So if y is equal to 1, then 1 minus y is 1 minus 1, which is therefore 0. So the second term gets multiplied by 0 and goes away. And we're left with only this first term, which is y times log- y times log (h(x)). Y is 1 so that's equal to -log h(x). And this equation is exactly what we have up here for if y = 1. The other case is if y = 0. And if that's the case, then our writing of the cos function is saying that, well, if y is equal to 0, then this term here would be equal to zero. Whereas 1 minus y, if y is equal to zero would be equal to 1, because 1 minus y becomes 1 minus zero which is just equal to 1. And so the cost function simplifies to just this last term here, right? Because the fist term over here gets multiplied by zero, and so it disappears, and so it's just left with this last term, which is -log (1- h(x)). And you can verify that this term here is just exactly what we had for when y is equal to 0.So this shows that this definition for the cost is just a more compact way of taking both of these expressions, the cases y =1 and y = 0, and writing them in a more convenient form with just one line. We can therefore write all our cost functions for logistic regression as follows. It is this 1 over m of the sum of these cost functions. And plugging in the definition for the cost that we worked out earlier, we end up with this. And we just put the minus sign outside. And why do we choose this particular function, while it looks like there could be other cost functions we could have chosen. Although I won't have time to go into great detail of this in this course, this cost function can be derived from statistics using the principle of maximum likelihood estimation. Which is an idea in statistics for how to efficiently find parameters' data for different models. And it also has a nice property that it is convex. So this is the cost function that essentially everyone uses when fitting logistic regression models. If you don't understand the terms that I just said, if you don't know what the principle of maximum likelihood estimation is, don't worry about it. But it's just a deeper rationale and justification behind this particular cost function than I have time to go into in this class. Given this cost function, in order to fit the parameters, what we're going to do then is try to find the parameters theta that minimize J of theta. So if we try to minimize this, this would give us some set of parameters theta. Finally, if we're given a new example with some set of features x, we can then take the thetas that we fit to our training set and output our prediction as this. And just to remind you, the output of my hypothesis I'm going to interpret as the probability that y is equal to one. And given the input x and parameterized by theta. But just, you can think of this as just my hypothesis as estimating the probability that y is equal to one.
### Classification_Graded Descent Simultaneously Update
![Classification_Graded Gescent Simultaneously Update](amWiki/images/001/03-Week3/1-Logistic Regression/24-分类问题_梯度下降同步更新.jpg)  
So all that remains to be done is figure out how to actually minimize J of theta as a function of theta so that we can actually fit the parameters to our training set. The way we're going to minimize the cost function is using gradient descent. Here's our cost function and if we want to minimize it as a function of theta, here's our usual template for graded descent where we repeatedly update each parameter by taking, updating it as itself minus learning ray alpha times this derivative term. If you know some calculus, feel free to take this term and try to compute the derivative yourself and see if you can simplify it to the same answer that I get. But even if you don't know calculus don't worry about it.
### Graded Descent in Linear Regression and Logistic Regression are same(Hypothesis different)
![Graded Descent in Linear Regression and Logistic Regression are same](amWiki/images/001/03-Week3/1-Logistic Regression/25-梯度下降算法在逻辑回归和线性回归中表示形式一致【假设函数不一致】.jpg)  
If you actually compute this, what you get is this equation, and just write it out here. It's sum from i equals one through m of essentially the error times xij. So if you take this partial derivative term and plug it back in here, we can then write out our gradient descent algorithm as follows.And all I've done is I took the derivative term for the previous slide and plugged it in there. So if you have n features, you would have a parameter vector theta, which with parameters theta 0, theta 1, theta 2, down to theta n. And you will use this update to simultaneously update all of your values of theta. Now, if you take this update rule and compare it to what we were doing for linear regression. You might be surprised to realize that, well, this equation was exactly what we had for linear regression. In fact, if you look at the earlier videos, and look at the update rule, the Gradient Descent rule for linear regression. It looked exactly like what I drew here inside the blue box. So are linear regression and logistic regression different algorithms or not? Well, this is resolved by observing that for logistic regression, what has changed is that the definition for this hypothesis has changed. So as whereas for linear regression, we had h(x) equals theta transpose X, now this definition of h(x) has changed. And is instead now one over one plus e to the negative transpose x. So even though the update rule looks cosmetically identical, because the definition of the hypothesis has changed, this is actually not the same thing as gradient descent for linear regression. In an earlier video, when we were talking about gradient descent for linear regression, we had talked about how to monitor a gradient descent to make sure that it is converging. I usually apply that same method to logistic regression, too to monitor a gradient descent, to make sure it's converging correctly. And hopefully, you can figure out how to apply that technique to logistic regression yourself.When implementing logistic regression with gradient descent, we have all of these different parameter values, theta zero down to theta n, that we need to update using this expression. And one thing we could do is have a for loop. So for i equals zero to n, or for i equals one to n plus one. So update each of these parameter values in turn. But of course rather than using a for loop, ideally we would also use a vector rise implementation. So that a vector rise implementation can update all of these m plus one parameters all in one fell swoop. And to check your own understanding, you might see if you can figure out how to do the vector rise implementation with this algorithm as well.So, now you you know how to implement gradient descents for logistic regression. There was one last idea that we had talked about earlier, for linear regression, which was feature scaling. We saw how feature scaling can help gradient descent converge faster for linear regression. The idea of feature scaling also applies to gradient descent for logistic regression. And yet we have features that are on very different scale, then applying feature scaling can also make grading descent run faster for logistic regression.So that's it, you now know how to implement logistic regression and this is a very powerful, and probably the most widely used, classification algorithm in the world. And you now know how we get it to work for yourself.
### 内置习题
![内置习题_逻辑回归模型中代价函数以及梯度下降函数化简形式](amWiki/images/001/03-Week3/1-Logistic Regression/26-内置习题_逻辑回归模型中代价函数以及梯度下降函数化简形式.jpg)
![内置习题_逻辑回归模型中参数theta向量化](amWiki/images/001/03-Week3/1-Logistic Regression/27-内置习题_逻辑回归模型中参数theta向量化.jpg)
