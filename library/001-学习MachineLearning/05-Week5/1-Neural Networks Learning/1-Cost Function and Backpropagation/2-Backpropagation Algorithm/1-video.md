# 神经网络学习-反向传播算法
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/05-Week5/1-Neural Networks Learning/2-Backpropagation Algorithm.mp4" type="video/mp4">
</video>
## 中文
### 引出问题_人工神经网络代价函数最小化
![引出问题_人工神经网络代价函数最小化](amWiki/images/001/05-Week5/1-Neural Networks Learning/5-引出问题_人工神经网络代价函数最小化.jpg)  
在上一个视频里 我们讲解了 神经网络的代价函数 在这个视频里 让我们来说说 让代价函数最小化的算法 具体来说 我们将主要讲解反向传播算法 这个就是我们上一个视频里写好的 代价函数 我们要做的就是 设法找到参数 使得J(θ)取到最小值 为了使用梯度下降法或者 其他某种高级优化算法 我们需要做的就是 写好一个可以通过输入 参数 θ 然后计算 J(θ) 和这些 偏导数项的代码 记住 这些神经网络里 对应的参数 也就是 θ 上标 (l) 下标 ij 的参数 这些都是实数 所以这些都是我们需要计算的 偏导数项 为了计算代价函数 J(θ) 我们就是用上面这个公式 所以我们在本节视频里大部分时间 想要做的都是 重点关注 如何计算这些 偏导数项
### 举例_单个训练样本下使用前向传播算法计算假设函数输出
![举例_单个训练样本下使用前向传播算法计算假设函数输出](amWiki/images/001/05-Week5/1-Neural Networks Learning/6-举例_单个训练样本下使用前向传播算法计算假设函数输出.jpg)  
我们从只有一个 训练样本的情况 开始说起 假设 我们整个训练集 只包含一个训练样本 也就是实数对 我这里不写成x(1) y(1) 就写成这样 把这一个训练样本记为 (x, y) 让我们粗看一遍 使用这一个训练样本 来计算的顺序 首先我们 应用前向传播方法来 计算一下在给定输入的时候 假设函数是否会真的输出结果 具体地说 这里的 a(1) 就是第一层的激励值 也就是输入层在的地方 所以我准备设定他为 然后我们来计算 z(2) 等于 θ(1) 乘以 a(1) 然后 a(2) 就等于 g(z(2)) 函数 其中g是一个S型激励函数 这就会计算出第一个 隐藏层的激励值 也就是神经网络的第二层 我们还增加这个偏差项 接下来我们再用2次 前向传播 来计算出 a(3) 和 最后的 a(4) 同样也就是假设函数 h(x) 的输出 所以这里我们实现了把前向传播 向量化 这使得我们可以计算 神经网络结构里的 每一个神经元的 激励值
### 使用反向传播算法计算代价函数偏导数项
![使用反向传播算法计算代价函数偏导数项](amWiki/images/001/05-Week5/1-Neural Networks Learning/7-使用反向传播算法计算代价函数偏导数项.jpg)  
接下来 为了计算导数项 我们将 采用一种叫做反向传播(Backpropagation)的算法 反向传播算法从直观上说 就是对每一个结点 我们计算这样一项 δ下标 j 上标(l) 这就用某种形式 代表了第 l 层的第 j 个结点的 误差 我们还记得 a 上标 (l) 下标 j 表示的是第 l 层第 j 个单元的 激励值 所以这个 δ 项 在某种程度上 就捕捉到了我们 在这个神经节点的激励值的误差 所以我们可能希望这个节点的 激励值稍微不一样 具体地讲 我们用 右边这个有四层 的神经网络结构做例子 所以这里大写 L 等于4 对于每一个输出单元 我们准备计算δ项 所以第四层的第j个单元的δ就等于 这个单元的激励值 减去训练样本里的 真实值0 所以这一项可以 同样可以写成 h(x) 下标 j 所以 δ 这一项就是 假设输出 和训练集y值 之间的差 这里 y 下标 j 就是 我们标记训练集里向量 的第j个元素的值顺便说一下 如果你把 δ a 和 y 这三个 都看做向量 那么你可以同样这样写 向量化地实现 也就是 δ(4)等于 a(4) 减去 y 这里 每一个变量 也就是 δ(4) a(4) 和 y 都是一个向量 并且向量维数等于 输出单元的数目 所以现在我们计算出 网络结构的 误差项 δ(4) 我们下一步就是计算 网络中前面几层的误差项 δ 这个就是计算 δ(3) 的公式 δ(3) 等于 θ(3) 的转置乘以 δ(4) 然后这里的点乘 这是我们从 MATLAB 里知道的 对 y 元素的乘法操作 所以 θ(3) 转置乘以 δ(4) 这是一个向量 g'(z(3)) 同样也是一个向量 所以点乘就是 两个向量的元素间对应相乘 其中这一项 g'(z(3)) 其实是对激励函数 g 在输入值为 z(3) 的时候 所求的 导数 如果你掌握微积分的话 你可以试着自己解出来 然后可以简化得到我这里的结果 但是我只是从实际角度告诉你这是什么意思 你计算这个 g' 这个导数项其实是 a(3) 点乘 (1-a(3)) 这里a(3)是 激励向量 1是以1为元素的向量 a(3) 又是 一个对那一层的 激励向量 接下来你应用一个相似的公式 来计算 δ(2) 同样这里可以利用一个 相似的公式 只是在这里 是 a(2) 这里我并没有证明 但是如果你懂微积分的话 证明是完全可以做到的 那么这个表达式从数学上讲 就等于激励函数 g函数的偏导数 这里我用 g‘来表示 最后 就到这儿结束了 这里没有 δ(1) 项 因为 第一次对应输入层 那只是表示 我们在训练集观察到的 所以不会存在误差 这就是说 我们是不想改变这些值的 所以这个例子中我们的 δ 项就只有 第2层和第3层 反向传播法这个名字 源于我们从 输出层开始计算 δ项 然后我们返回到上一层 计算第三隐藏层的 δ项 接着我们 再往前一步来计算 δ(2) 所以说 我们是类似于把输出层的误差 反向传播给了第3层 然后是再传到第二层 这就是反向传播的意思 最后 这个推导过程是出奇的麻烦的 出奇的复杂 但是如果你按照 这样几个步骤计算 就有可能简单直接地完成 复杂的数学证明 如果你忽略标准化所产生的项 我们可以证明 我们要求的偏导数项 恰好就等于 激励函数和这些 δ 项 这里我们忽略了 λ 或者说 标准化项 λ 是等于 0 我们将在之后完善这一个 关于正则化项 所以到现在 我们通过 反向传播 计算这些δ项 可以非常快速的计算出 所有参数的 偏导数项 好了 现在讲了很多细节了
### 小结_人工神经网络最小化代价函数过程
![小结_人工神经网络最小化代价函数过程](amWiki/images/001/05-Week5/1-Neural Networks Learning/8-小结_人工神经网络最小化代价函数过程.jpg)  
现在让我们把所有内容整合在一起 然后说说 如何实现反向传播算法 来计算关于这些参数的偏导数 当我们有 一个非常大的训练样本时 而不是像我们例子里这样的一个训练样本 我们是这样做的 假设我们有 m 个样本的训练集 正如此处所写 我要做的第一件事就是 固定这些 带下标 i j 的 Δ 这其实是 大写的希腊字母 δ 我们之前写的那个是小写 这个三角形是大写的 Δ 我们将对每一个i 和 j 对应的 Δ 等于0 实际上 这些大写 Δij 会被用来计算 偏导数项 就是 J(θ) 关于 θ 上标(l) 下标 i j 的 偏导数 所以 正如我们接下来看到的 这些 δ 会被作为累加项 慢慢地增加 以算出这些偏导数 接下来我们将遍历我们的训练集 我们这样写 写成 For i = 1 to m 对于第 i 个循环而言 我们将取训练样本 (x(i), y(i)) 我把1999年的值画在一列里 我们要做的第一件事是 设定a(1) 也就是 输入层的激励函数 设定它等于 x(i) x(i) 是我们第 i 个训练样本的 输入值 接下来我们运用正向传播 来计算第二层的激励值 然后是第三层 第四层 一直这样 到最后一层 L层 接下来 我们将用 我们这个样本的 输出值 y(i) 来计算这个输出值 所对应的误差项 δ(L) 所以 δ(L) 就是 假设输出减去 目标输出 接下来 我们将 运用反向传播算法 来计算 δ(L-1) δ(L-2) 一直这样直到 δ(2) 再强调一下 这里没有 δ(1) 因为我们不需要对输入层考虑误差项 最后我们将用 这些大写的 Δ 来累积我们在前面写好的 偏导数项 顺便说一下 如果你再看下这个表达式 你可以把它写成向量形式 具体地说 如果你把 δij 看作一个矩阵 i j代表矩阵中的位置 那么 如果 δ(L) 是一个矩阵 我们就可以写成 Δ(l) 等于 Δ(l) 加上 小写的 δ(l+1) 乘以 a(l) 的转置 这就是用向量化的形式 实现了对所有 i 和 j 的自动更新值 最后 执行这个 for 循环体之后 我们跳出这个 for 循环 然后计算下面这些式子 我们按照如下公式计算 大写 我们对于 j=0 和 j≠0 分两种情况讨论在 j=0 的情况下 对应偏差项 所以当 j=0 的时候 这就是为什么 我们没有写额外的标准化项 最后 尽管严格的证明对于 你来说太复杂 你现在可以说明的是 一旦你计算出来了这些 这就正好是 代价函数对 每一个参数的偏导数 所以你可以把他们用在 梯度下降法 或者其他一种更高级的 优化算法上这就是反向传播算法 以及你如何计算 神经网络代价函数的 偏导数 我知道这个里面 细节琐碎 步骤繁多 但是在后面的编程作业 和后续的视频里 我都会给你一个 清晰的总结 这样我们就可以把算法的所有细节 拼合到一起 这样 当你想运用反向传播算法 来计算你的神经网络的代价函数 关于这些参数的偏导数的时候 你就会清晰地知道 你要的是什么
### 内置习题
![内置习题_理解神经网络算法最小化代价函数过程](amWiki/images/001/05-Week5/1-Neural Networks Learning/9-内置习题_理解神经网络算法最小化代价函数过程.jpg)
## English
### A problems_Artificial Neural Networks to Minimize the cost function
![A problems_Artificial Neural Networks to Minimize the cost function](amWiki/images/001/05-Week5/1-Neural Networks Learning/5-引出问题_人工神经网络代价函数最小化.jpg)  
In the previous video, we talked about a cost function for the neural network. In this video, let's start to talk about an algorithm, for trying to minimize the cost function. In particular, we'll talk about the back propagation algorithm.Here's the cost function that we wrote down in the previous video. What we'd like to do is try to find parameters theta to try to minimize j of theta. In order to use either gradient descent or one of the advance optimization algorithms. What we need to do therefore is to write code that takes this input the parameters theta and computes j of theta and these partial derivative terms. Remember, that the parameters in the the neural network of these things, theta superscript l subscript ij, that's the real number and so, these are the partial derivative terms we need to compute. In order to compute the cost function j of theta, we just use this formula up here and so, what I want to do for the most of this video is focus on talking about how we can compute these partial derivative terms.
### Example_Using Forward Propagation Algorithm Calculate the output of H(x)
![Example_Using Forward Propagation Algorithm Calculate the output of H(x)](amWiki/images/001/05-Week5/1-Neural Networks Learning/6-举例_单个训练样本下使用前向传播算法计算假设函数输出.jpg)
Let's start by talking about the case of when we have only one training example, so imagine, if you will that our entire training set comprises only one training example which is a pair xy. I'm not going to write x1y1 just write this. Write a one training example as xy and let's tap through the sequence of calculations we would do with this one training example.The first thing we do is we apply forward propagation in order to compute whether a hypotheses actually outputs given the input. Concretely, the called the a(1) is the activation values of this first layer that was the input there. So, I'm going to set that to x and then we're going to compute z(2) equals theta(1) a(1) and a(2) equals g, the sigmoid activation function applied to z(2) and this would give us our activations for the first middle layer. That is for layer two of the network and we also add those bias terms. Next we apply 2 more steps of this four and propagation to compute a(3) and a(4) which is also the upwards of a hypotheses h of x. So this is our vectorized implementation of forward propagation and it allows us to compute the activation values for all of the neurons in our neural network.
### Using Back propagation algorithm calculate the cost function partial derivative
![Using Back propagation algorithm calculate the cost function partial derivative](amWiki/images/001/05-Week5/1-Neural Networks Learning/7-使用反向传播算法计算代价函数偏导数项.jpg)  
Next, in order to compute the derivatives, we're going to use an algorithm called back propagation.The intuition of the back propagation algorithm is that for each note we're going to compute the term delta superscript l subscript j that's going to somehow represent the error of note j in the layer l. So, recall that a superscript l subscript j that does the activation of the j of unit in layer l and so, this delta term is in some sense going to capture our error in the activation of that neural duo. So, how we might wish the activation of that note is slightly different. Concretely, taking the example neural network that we have on the right which has four layers. And so capital L is equal to 4. For each output unit, we're going to compute this delta term. So, delta for the j of unit in the fourth layer is equal to just the activation of that unit minus what was the actual value of 0 in our training example.So, this term here can also be written h of x subscript j, right. So this delta term is just the difference between when a hypotheses output and what was the value of y in our training set whereas y subscript j is the j of element of the vector value y in our labeled training set.And by the way, if you think of delta a and y as vectors then you can also take those and come up with a vectorized implementation of it, which is just delta 4 gets set as a4 minus y. Where here, each of these delta 4 a4 and y, each of these is a vector whose dimension is equal to the number of output units in our network.So we've now computed the era term's delta 4 for our network.What we do next is compute the delta terms for the earlier layers in our network. Here's a formula for computing delta 3 is delta 3 is equal to theta 3 transpose times delta 4. And this dot times, this is the element y's multiplication operation that we know from MATLAB. So delta 3 transpose delta 4, that's a vector; g prime z3 that's also a vector and so dot times is in element y's multiplication between these two vectors.This term g prime of z3, that formally is actually the derivative of the activation function g evaluated at the input values given by z3. If you know calculus, you can try to work it out yourself and see that you can simplify it to the same answer that I get. But I'll just tell you pragmatically what that means. What you do to compute this g prime, these derivative terms is just a3 dot times1 minus A3 where A3 is the vector of activations. 1 is the vector of ones and A3 is again the activation the vector of activation values for that layer. Next you apply a similar formula to compute delta 2 where again that can be computed using a similar formula.Only now it is a2 like so and I then prove it here but you can actually, it's possible to prove it if you know calculus that this expression is equal to mathematically, the derivative of the g function of the activation function, which I'm denoting by g prime. And finally, that's it and there is no delta1 term, because the first layer corresponds to the input layer and that's just the feature we observed in our training sets, so that doesn't have any error associated with that. It's not like, you know, we don't really want to try to change those values. And so we have delta terms only for layers 2, 3 and for this example.The name back propagation comes from the fact that we start by computing the delta term for the output layer and then we go back a layer and compute the delta terms for the third hidden layer and then we go back another step to compute delta 2 and so, we're sort of back propagating the errors from the output layer to layer 3 to their to hence the name back complication.Finally, the derivation is surprisingly complicated, surprisingly involved but if you just do this few steps steps of computation it is possible to prove viral frankly some what complicated mathematical proof. It's possible to prove that if you ignore authorization then the partial derivative terms you want are exactly given by the activations and these delta terms. This is ignoring lambda or alternatively the regularization term lambda will equal to 0. We'll fix this detail later about the regularization term, but so by performing back propagation and computing these delta terms, you can, you know, pretty quickly compute these partial derivative terms for all of your parameters. So this is a lot of detail.
### Summary_Process of Artificial Neural Networks to minimize the cost function
![Summary_Process of Artificial Neural Networks to minimize the cost function](amWiki/images/001/05-Week5/1-Neural Networks Learning/8-小结_人工神经网络最小化代价函数过程.jpg)  
Let's take everything and put it all together to talk about how to implement back propagation to compute derivatives with respect to your parameters.And for the case of when we have a large training set, not just a training set of one example, here's what we do. Suppose we have a training set of m examples like that shown here. The first thing we're going to do is we're going to set these delta l subscript i j. So this triangular symbol? That's actually the capital Greek alphabet delta . The symbol we had on the previous slide was the lower case delta. So the triangle is capital delta. We're gonna set this equal to zero for all values of l i j. Eventually, this capital delta l i j will be used to compute the partial derivative term, partial derivative respect to theta l i j of J of theta.So as we'll see in a second, these deltas are going to be used as accumulators that will slowly add things in order to compute these partial derivatives.Next, we're going to loop through our training set. So, we'll say for i equals 1 through m and so for the i iteration, we're going to working with the training example xi, yi.So the first thing we're going to do is set a1 which is the activations of the input layer, set that to be equal to xi is the inputs for our i training example, and then we're going to perform forward propagation to compute the activations for layer two, layer three and so on up to the final layer, layer capital L. Next, we're going to use the output label yi from this specific example we're looking at to compute the error term for delta L for the output there. So delta L is what a hypotheses output minus what the target label was? And then we're going to use the back propagation algorithm to compute delta L minus 1, delta L minus 2, and so on down to delta 2 and once again there is now delta 1 because we don't associate an error term with the input layer.And finally, we're going to use these capital delta terms to accumulate these partial derivative terms that we wrote down on the previous line.And by the way, if you look at this expression, it's possible to vectorize this too. Concretely, if you think of delta ij as a matrix, indexed by subscript ij.Then, if delta L is a matrix we can rewrite this as delta L, gets updated as delta L plus lower case delta L plus one times aL transpose. So that's a vectorized implementation of this that automatically does an update for all values of i and j. Finally, after executing the body of the four-loop we then go outside the four-loop and we compute the following. We compute capital D as follows and we have two separate cases for j equals zero and j not equals zero.The case of j equals zero corresponds to the bias term so when j equals zero that's why we're missing is an extra regularization term.Finally, while the formal proof is pretty complicated what you can show is that once you've computed these D terms, that is exactly the partial derivative of the cost function with respect to each of your perimeters and so you can use those in either gradient descent or in one of the advanced authorization algorithms.So that's the back propagation algorithm and how you compute derivatives of your cost function for a neural network. I know this looks like this was a lot of details and this was a lot of steps strung together. But both in the programming assignments write out and later in this video, we'll give you a summary of this so we can have all the pieces of the algorithm together so that you know exactly what you need to implement if you want to implement back propagation to compute the derivatives of your neural network's cost function with respect to those parameters.
### Exam_in the video
![Exam_Understand the process of neural network algorithm to minimize the cost function](amWiki/images/001/05-Week5/1-Neural Networks Learning/9-内置习题_理解神经网络算法最小化代价函数过程.jpg)
