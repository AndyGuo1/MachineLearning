# 神经网络学习-反向传播算法直观感受
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/05-Week5/1-Neural Networks Learning/3-Backpropagation Intuition.mp4" type="video/mp4">
</video>
## 中文
### 前向传播算法
![前向传播算法](amWiki/images/001/05-Week5/1-Neural Networks Learning/11-前向传播算法.jpg)  
在之前的视频里，我们介绍了反向传播算法 对许多人来说， 第一次看到它的印象是，这是一个非常复杂的算法 并且这里有很多步骤，人们很难搞清楚是怎么统一起来 看起来像是一个复杂的黑箱 如果你也是这么觉得，其实很正常 反向传播，很大程度上数学步骤比较复杂 并不是一个简单的算法 比起线性回归和逻辑回归而言。 我实际上使用反向传播算法许多年， 也很成功。 但即使是今天，有时候我还是感觉不太好把握， 或者忽然觉得迷茫。 因此，对于即将做编程的同学， 你们不用担心，我们会有数学的具体步骤， 它将帮助你来一步一步完成。 所以，你将能够自主独立实现。 在这个视频，我要做的， 是再一步一步介绍这个算法，让你更有体会。 这些机械的步骤，将使你信服， 让你认为这是一个非常合理的算法。如果这个视频之后， 你还是觉得这个算法非常复杂， 其实也没有太大关系。 正如之前所说，对我而言有时候也很难。 但，希望这个视频可以有所帮助。 为了更好地理解反向传播算法， 我们来看看正向传播 这个神经网络有两个输入层单元，当然不算上偏置单元 两个隐层单元，有两层 还有一个输出单元 当然，我们都不算偏置单元
### 前向传播算法计算
![前向传播算法计算](amWiki/images/001/05-Week5/1-Neural Networks Learning/12-前向传播算法计算.jpg)  
为了更好地展示前向传播 我这次要用另外一种画法 特别地，我要把每个神经元 画的更扁平一些，所以我可以在里面写字 当进行前向传播算法的时候，我们可能有一些特别的例子 比如，xi，yi 我们将把它输入到这个网络当中 所以，xi1和xi2将是我们对输入层的设置 当我们进入第一个隐层， 我们会计算z(2)1和z(2)2 那么，这些是我们要的值 然后我们来用冲击函数计算 它作用与z值 这里是激励值 所以我们有a(2)1和a(2)2 之后我们把这些值赋予给z(3)1 然后使用sigmoid函数 我们会得到a(3)1 类似的，我们一直得到z(4)1 再次计算， 我们有a(4)1，这是最后的结果 我们擦掉这些箭头，来得到更多空间 如果你仔细看我们的计算过程， 我们可以说， 我们要加上这个权重 (2)1 0，这里的编号不重要 这个方向，我用红色高亮 是theta(2)11以及权重 这里用青色标注theta(2)12 所以，z(3)1是 z(3)1等于这个值 所以我们有(2)10x1 然后加上红色标注的权值 得到theta(2)11乘以a(2)1 最后我们再用青色来乘 也就是加上theta(2)12乘以a(2)1 那么这就是前向传播 这我们之前看到过
### 理解反向传播算法在做什么
![理解反向传播算法在做什么](amWiki/images/001/05-Week5/1-Neural Networks Learning/13-理解反向传播算法在做什么.jpg)  
而反向传播做的很类似 除了这些计算从左到右， 现在是从右到左 同时计算流程相似 我用两页PPT来描述这个过程 首先来看其支付函数 这是只有一个输出单元时候的支付函数 如果有多个 那就需要编号并且求和 如果只有一个，用这个函数就行 我们在一个例子里做前向和后向传播 来关注一个例子x(i)和y(i) 并且来看输出值 所以y(i)是一个实数 我们现在不考虑标准化，所以lambda为0 所以最后一项去掉 如果你来看这个求和公式 你会发现，这个支付项 和我们的训练数据x(i)和y(i)有关 这由我们的表达式给出 所以，正如下述所写的 支付函数所做的和这个箭头相似 我们不看这个复杂的表达式 如果你考虑支付， 这里就是我们的插值 和之前逻辑回归很像， 我们用了Log 但，从直觉上来说， 这其实就是平方误差函数 所以cost(i)描述了 这个网络的表现，对于特定的结果i 那么到底这个计算结果和真实值y(i)多接近呢 我们来看反向传播在做什么 一个很有用的例子就是反向传播 计算了deltai下标j 这是我们的理解方法， 我们在l层得到单元j 正式一点说， 这个对于熟悉微积分的人来说更恰当 所以，这就是delta项 它就是一个偏微分，针对z,l,j 这是权重， 针对这些量的偏微分，所得到的支付函数 所以，具体来说， 这个h x输出值， 如果我们走进这个神经网络， 并且只稍微改变一下zl j值 那么这就会改变我们的输出 也会改变我们的支付函数 同样，还是针对那些微积分比较好的同学 如果你适应偏微分 这些就是对支付函数的偏微分， 针对中间变量 并且，他们衡量了我们要如果改变网络的权值 当然，这是为了影响我们的计算结果 所以，为了改变计算结果h(x) 以及对整个支付函数的影响 上下的这个偏微分的理解， 如果你不能理解 不要太担心 我们可以撇开它来谈
### 通过类比前向传播算法理解反向传播算法执行步骤
![通过类比前向传播算法理解反向传播算法执行步骤](amWiki/images/001/05-Week5/1-Neural Networks Learning/14-通过类比前向传播算法理解反向传播算法执行步骤.jpg)  
我们就来看看到底反向传播算法做了什么 首先，设置这个delta项 delta(4) 1正如y(i)我们对前向传播算法 和后向传播对训练数据i的做法一样。 这表达的是y(i)减去a(4)1 所以就是误差，对吧 这就是真实结果和 我们预测结果的误差，所以我们结算delta(4)1 接下来，我们来把这些值反向传播回去 我会马上解释， 这最后就是计算前向的结果 我们会得到delta(3)1 delta3(2) 然后，我们进一步往前， 得到delta(2)1和delta(2)2 现在 看起来就像是又重演前向传播 只不过我们现在反过来做了，这就是我之前所说的 我们来看看最后我们如何得到delta(2)2 所以我们得到delta(2)2 和前向传播类似， 这个权值，我用青色来表示 加入它是theta(2)12 然后，我用红色来高亮 这个我们说是theta(2) 22 如果，我们来看delta(2)2 如何计算。 结果，我们发现 我们就把这个值乘以它权值，并加上这个值乘以权值 所以，就是一个加权求和 权值是每一条边的强度 所以，我们来看delta(2)2 theta(2)12是delta(3)1 加上 我们红色标注的东西 theta(2)2乘以delta(3)2 所以，这个红色值乘以这个值 加上品红色的权值 恩， 另一个例子，我们来看这个值怎么求 如果得到呢 恩，一样的步骤 如果这个权值，我用绿色来描述 它等于delta(3)12 然后我们有delta(3)2将等于它的绿色权值 theta(3)12乘以delta(4)1 顺便一提，我只写隐层单元 忽略了偏置单元 这要看你如何定义算法 或者你如何应用 你也可能要用这些单元 这些偏置单元总是为1 所以他们就是1，我们不会改变他们 所以，要看你的应用思路 以及使用方法 我们计算完了这些值 我们扔掉它， 因为我们最后得到的不过是 计算导数的一个部分 希望这就可以给一个更好的直观体会 关于反向传播算法 如果仍然感觉很迷茫， 像是黑箱，在下一个视频 我会再把他们总结起来 但，这是一个很难讲解的算法 难以可视化 但， 幸运的是很多人都在成功使用它 如果你使用这个算法 它将是非常有效的，尽管它内部的机制很难可视化。
### 内置习题
![内置习题_理解反向传播算法](amWiki/images/001/05-Week5/1-Neural Networks Learning/15-内置习题_理解反向传播算法.jpg)
## English
### The forward propagation algorithm
![The forward propagation algorithm](amWiki/images/001/05-Week5/1-Neural Networks Learning/11-前向传播算法.jpg)  
In the previous video, we talked about the backpropagation algorithm. To a lot of people seeing it for the first time, their first impression is often that wow this is a really complicated algorithm, and there are all these different steps, and I'm not sure how they fit together. And it's kinda this black box of all these complicated steps. In case that's how you're feeling about backpropagation, that's actually okay. Backpropagation maybe unfortunately is a less mathematically clean, or less mathematically simple algorithm, compared to linear regression or logistic regression. And I've actually used backpropagation, you know, pretty successfully for many years. And even today I still don't sometimes feel like I have a very good sense of just what it's doing, or intuition about what back propagation is doing. If, for those of you that are doing the programming exercises, that will at least mechanically step you through the different steps of how to implement back prop. So you'll be able to get it to work for yourself. And what I want to do in this video is look a little bit more at the mechanical steps of backpropagation, and try to give you a little more intuition about what the mechanical steps the back prop is doing to hopefully convince you that, you know, it's at least a reasonable algorithm.In case even after this video in case back propagation still seems very black box and kind of like a, too many complicated steps and a little bit magical to you, that's actually okay. And Even though I've used back prop for many years, sometimes this is a difficult algorithm to understand, but hopefully this video will help a little bit.In order to better understand backpropagation, let's take another closer look at what forward propagation is doing. Here's a neural network with two input units that is not counting the bias unit, and two hidden units in this layer, and two hidden units in the next layer. And then, finally, one output unit. Again, these counts two, two, two, are not counting these bias units on top.
### Forward Propagation Algorithm Calculation
![Forward Propagation Algorithm Calculation](amWiki/images/001/05-Week5/1-Neural Networks Learning/12-前向传播算法计算.jpg)  
In order to illustrate forward propagation, I'm going to draw this network a little bit differently.And in particular I'm going to draw this neuro-network with the nodes drawn as these very fat ellipsis, so that I can write text in them. When performing forward propagation, we might have some particular example. Say some example x i comma y i. And it'll be this x i that we feed into the input layer. So this maybe x i 2 and x i 2 are the values we set the input layer to. And when we forward propagated to the first hidden layer here, what we do is compute z (2) 1 and z (2) 2. So these are the weighted sum of inputs of the input units. And then we apply the sigmoid of the logistic function, and the sigmoid activation function applied to the z value. Here's are the activation values. So that gives us a (2) 1 and a (2) 2. And then we forward propagate again to get here z (3) 1. Apply the sigmoid of the logistic function, the activation function to that to get a (3) 1. And similarly, like so until we get z (4) 1. Apply the activation function. This gives us a (4)1, which is the final output value of the neural network.Let's erase this arrow to give myself some more space. And if you look at what this computation really is doing, focusing on this hidden unit, let's say. We have to add this weight. Shown in magenta there is my weight theta (2) 1 0, the indexing is not important. And this way here, which I'm highlighting in red, that is theta (2) 1 1 and this weight here, which I'm drawing in cyan, is theta (2) 1 2. So the way we compute this value, z(3)1 is, z(3)1 is as equal to this magenta weight times this value. So that's theta (2) 10 x 1. And then plus this red weight times this value, so that's theta(2) 11 times a(2)1. And finally this cyan weight times this value, which is therefore plus theta(2)12 times a(2)1. And so that's forward propagation.
### Understand what backpropagation is doing
![Understand what backpropagation is doing](amWiki/images/001/05-Week5/1-Neural Networks Learning/13-理解反向传播算法在做什么.jpg)  
what backpropagation is doing is doing a process very similar to this. Except that instead of the computations flowing from the left to the right of this network, the computations since their flow from the right to the left of the network. And using a very similar computation as this. And I'll say in two slides exactly what I mean by that. To better understand what backpropagation is doing, let's look at the cost function. It's just the cost function that we had for when we have only one output unit. If we have more than one output unit, we just have a summation you know over the output units indexed by k there. If you have only one output unit then this is a cost function. And we do forward propagation and backpropagation on one example at a time. So let's just focus on the single example, x (i) y (i) and focus on the case of having one output unit. So y (i) here is just a real number. And let's ignore regularization, so lambda equals 0. And this final term, that regularization term, goes away. Now if you look inside the summation, you find that the cost term associated with the training example, that is the cost associated with the training example x(i), y(i). That's going to be given by this expression. So, the cost to live off examplie i is written as follows. And what this cost function does is it plays a role similar to the squared arrow. So, rather than looking at this complicated expression, if you want you can think of cost of i being approximately the square difference between what the neural network outputs, versus what is the actual value. Just as in logistic repression, we actually prefer to use the slightly more complicated cost function using the log. But for the purpose of intuition, feel free to think of the cost function as being the sort of the squared error cost function. And so this cost(i) measures how well is the network doing on correctly predicting example i. How close is the output to the actual observed label y(i)? Now let's look at what backpropagation is doing. One useful intuition is that backpropagation is computing these delta superscript l subscript j terms. And we can think of these as the quote error of the activation value that we got for unit j in the layer, in the lth layer.More formally, for, and this is maybe only for those of you who are familiar with calculus. More formally, what the delta terms actually are is this, they're the partial derivative with respect to z,l,j, that is this weighted sum of inputs that were confusing these z terms. Partial derivatives with respect to these things of the cost function.So concretely, the cost function is a function of the label y and of the value, this h of x output value neural network. And if we could go inside the neural network and just change those z l j values a little bit, then that will affect these values that the neural network is outputting. And that will end up changing the cost function. And again really, this is only for those of you who are expert in Calculus. If you're comfortable with partial derivatives, what these delta terms are is they turn out to be the partial derivative of the cost function, with respect to these intermediate terms that were confusing.And so they're a measure of how much would we like to change the neural network's weights, in order to affect these intermediate values of the computation. So as to affect the final output of the neural network h(x) and therefore affect the overall cost. In case this lost part of this partial derivative intuition, in case that doesn't make sense. Don't worry about the rest of this, we can do without really talking about partial derivatives.
### By analogy to the forward propagation algorithm understanding step back propagation algorithm
![By analogy to the forward propagation algorithm understanding step back propagation algorithm](amWiki/images/001/05-Week5/1-Neural Networks Learning/14-通过类比前向传播算法理解反向传播算法执行步骤.jpg)  
But let's look in more detail about what backpropagation is doing. For the output layer, the first set's this delta term, delta (4) 1, as y (i) if we're doing forward propagation and back propagation on this training example i. That says y(i) minus a(4)1. So this is really the error, right? It's the difference between the actual value of y minus what was the value predicted, and so we're gonna compute delta(4)1 like so. Next we're gonna do, propagate these values backwards. I'll explain this in a second, and end up computing the delta terms for the previous layer. We're gonna end up with delta(3)1. Delta(3)2. And then we're gonna propagate this further backward, and end up computing delta(2)1 and delta(2)2. Now the backpropagation calculation is a lot like running the forward propagation algorithm, but doing it backwards. So here's what I mean. Let's look at how we end up with this value of delta(2)2. So we have delta(2)2. And similar to forward propagation, let me label a couple of the weights. So this weight, which I'm going to draw in cyan. Let's say that weight is theta(2)1 2, and this one down here when we highlight this in red. That is going to be let's say theta(2) of 2 2. So if we look at how delta(2)2, is computed, how it's computed with this note. It turns out that what we're going to do, is gonna take this value and multiply it by this weight, and add it to this value multiplied by that weight. So it's really a weighted sum of these delta values, weighted by the corresponding edge strength. So completely, let me fill this in, this delta(2)2 is going to be equal to, Theta(2)1 2 is that magenta lay times delta(3)1. Plus, and the thing I had in red, that's theta (2)2 times delta (3)2. So it's really literally this red wave times this value, plus this magenta weight times this value. And that's how we wind up with that value of delta. And just as another example, let's look at this value. How do we get that value? Well it's a similar process. If this weight, which I'm gonna highlight in green, if this weight is equal to, say, delta (3) 1 2. Then we have that delta (3) 2 is going to be equal to that green weight, theta (3) 12 times delta (4) 1. And by the way, so far I've been writing the delta values only for the hidden units, but excluding the bias units. Depending on how you define the backpropagation algorithm, or depending on how you implement it, you know, you may end up implementing something that computes delta values for these bias units as well. The bias units always output the value of plus one, and they are just what they are, and there's no way for us to change the value. And so, depending on your implementation of back prop, the way I usually implement it. I do end up computing these delta values, but we just discard them, we don't use them. Because they don't end up being part of the calculation needed to compute a derivative. So hopefully that gives you a little better intuition about what back propegation is doing. In case of all of this still seems sort of magical, sort of black box, in a later video, in the putting it together video, I'll try to get a little bit more intuition about what backpropagation is doing. But unfortunately this is a difficult algorithm to try to visualize and understand what it is really doing. But fortunately I've been, I guess many people have been using very successfully for many years. And if you implement the algorithm you can have a very effective learning algorithm. Even though the inner workings of exactly how it works can be harder to visualize.
### Exam_in the video
![Exam_Understand Backpropagation algorithm](amWiki/images/001/05-Week5/1-Neural Networks Learning/15-内置习题_理解反向传播算法.jpg)
