# 神经网络学习- 梯度检查
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/05-Week5/1-Neural Networks Learning/5-Gradient Checking.mp4" type="video/mp4">
</video>
## 中文
### 当 Θ 是一个向量时的梯度检验
![当 Θ 是一个向量时的梯度检验](amWiki/images/001/05-Week5/1-Neural Networks Learning/22-当 Θ 是一个向量时的梯度检验.jpg)  
在之前几个视频里，我们讨论了如何进行前向传播 以及后向传播，从而计算导数 但，后向传播有很多细节， 这些细节有点复杂 有一个不幸的消息是， 它们有很多细节会导致一些BUG 如果你用梯度下降来计算， 你会发现表面上它可以工作 实际上， J 虽然每次迭代都在下降 但是可能， 仍然你的代码有很多BUG 所以，表面上关于theta的函数J在减小 但是你可能最后得到的结果 实际上有很大的误差 你这时候可能知道，有一些小的BUG导致 这种不好的算法性能表现 所以，怎么办呢 有一个想法叫梯度检验 Gradient Checking 它能减少这种错误的概率 就我个人而言，每次我使用后向传播 我都会[]用这种方法 即使是其他比较复杂的模型，我都会做这种检查 如果你这么做，你会对你的模型更有自信 这样，你会更加确信的模型是100%正确的 从我看到的情况，这种方法， 很大程度可以减少错误的可能性 在之前的视频里，我让你们相信 我给你们的公式是正确的， 我还让你们相信，这就是支付函数的梯度值 但，一旦你使用梯度检验， 也就是我们这个视频的主题，你会证明你的代码 实际上就是梯度函数 所以，这就是我们的想法，来看一个例子 假设我们有一个关于theta的函数H 我现在有它的一个值，假设是实数 我们说，我想要预测它的倒数， 所以倒数是等于这里的斜度 现在我用这种方法来接近， 我们不采用数值的计算倒数， 这里我用epsilon， 同样也有一个减去epsilon的值 然后把他们链接起来 我将得到一条直线 我用这个红色线来近似我的导数 恩，真正的斜率是蓝色的线。 所以，你可以看到这是一个很好的近似。数学上，这里的红线垂直高度 除以这个水平宽度，就是我们的斜率 所以，这个点，就是J() 这个点，(theta减掉epsilon) 我们有一个垂直的差值()减去 这两个点的差值，以及水平宽度2epsilon 所以我们可以近似来表示 这是近似的值， 它等于J加上epsilon减去J减去epsilon对应的函数值，除以2倍的epsilon 通常， 这个epsilon非常小，可能就是10的-4次方 而误差值往往很大， 所以近似效果很好。实际上 如果让epsilon无穷小，这就是导数的定义 恩，它就是导数。 所以， 但我们不希望epsilon太小，否则会有计算上的问题 一般来说在10的-4次方比较合适 通常，你可能见到这个类似的公式 恩。所以，右边的叫做单边导数 左边的叫做双边导数 后者的精确度更高， 当然，一般我们用后者 所以，具体来说，当你用octave， 你计算近似梯度时候， 我们用的是这个公式。 恩。。就是红色标注的双边导数近似公式，除以的是2倍 所以，我们有一个近似的值 在这个例子，它看起来非常好地近似我们的结果
### 当 Θ 是一个矩阵时的梯度检验
![当 Θ 是一个矩阵时的梯度检验](amWiki/images/001/05-Week5/1-Neural Networks Learning/23-当 Θ 是一个矩阵时的梯度检验.jpg)  
在之前的PPT里 我们考虑了theta是一个向量 现在，我们来看一般的情况 我们说theta是一个矩阵 我们有一个舒展的参数版本， 所以，这里theta是从1到n的向量 我们， 可以用近似的方式来进行计算 可以看到，我们列出各个近似的求导公式 theta 1套前面的公式是这样， 如此种种。 恩。。 这里都是偏导数。 只改变theta 1的值，其他的值固定 分母一样，还是2 epsilon 我们现在可以得到我们想要的近似结果 恩，所以这个公式组给出了近似的方法 对于任意一个theta我们都有 完整地，你可以这样应用。
### 在Octave中实现梯度检验代码
![在Octave中实现梯度检验代码](amWiki/images/001/05-Week5/1-Neural Networks Learning/24-在Octave中实现梯度检验代码.jpg)  
我们用octave来数值计算， 比如， 对于i=1:n，其中n是我们参数的个数 一般我们习惯是舒展的向量而不是矩阵 所以theta是长长的参数清单  这里设置thetaPlus = theta 之后增加(i)项epsilon 恩，这就等于我们 thetaPlus(i)， theta1, theta2如此种种 thetal ，一直到N 所以，这是thetaPlus的含义 类似的 我们现在也有l 减去epsilon 最后你会使用这个gradApprox(i) 并且能够给你一个偏微分单数 对于i 这就是我们使用的方法 我们可以用一个循环来写 来检验这个近似计算的结果是不是等于我们的计算结果 也就是反向传播算法计算的梯度 Dvec就是我们得到的导数 好的， 反向传播是一个非常高效的算法， 针对所有的参数 我们通常做的是数值计算的结果 也就是刚才所做的 确信这是相等的， 应该说非常接近 所以DVec，我们从反向传播得到， 如果得到同一个结果 或者相近的结果，只相差一些小数位 我们很确信这个反向传播的算法是正确的 如果我代入梯度计算 一些高级的算法 我们会更加确信我们的导数计算是正确的 因此，我们的代码不仅正确，而且在优化上性能很好
### 反向传播算法中梯度检验注意细节
![反向传播算法中梯度检验注意细节](amWiki/images/001/05-Week5/1-Neural Networks Learning/25-反向传播算法中梯度检验注意细节.jpg)  
最后，我想总结一下 告诉你梯度检验的相关内容 这是我通常做的事情 首先，使用反向传播来计算，它是很好的算法 这里就是前面介绍的流程 这里的参数我们把矩阵展开成向量 然后 我们使用数值的梯度来检验 这是刚刚介绍的内容 我们要确信这两个方法算出来结果一致 你知道，就差一点 最后，也是最重要的步骤 就是在你开始学习之前， 一定要关掉我们的梯度检验， 也就是我们讨论的数值计算方法 原因是这个计算过程， 实际上代价更高，复杂度也很高 这不是一个很好的计算导数的方法 相反，我们前面讨论的反向传播算法 很早以前介绍的内容 你知道D1 D2 D3对于DVEC 相对来说非常高效。 恩 所以，一旦你检验证明你的算法没有错误 就要把梯度检验关掉 所以，你一定要关掉 在你开始迭代训练之前 对于其他很多优化算法也一样 为了训练你的分类器 具体来说，如果你一定要用数值方法 来计算梯度， 那么你的算法会非常慢。 在你的支付函数的循环过程当中 因为，正如前面所说 我们再重复一下...它很慢 记得，我们这里计算(4)(3)(2)等等 这是我们的反向传播算法 它快得多 所以，再说一遍...检验完了后向传播没有问题 关掉梯度检验，重要的事情说三遍 当你在训练你的算法的时候，所以数值的计算， 这是你的检验方法而已。 对我而言，每当我要使用梯度算法，比如后向传播 我都会用梯度检验一下这个算法是否正确 这会让我更加自信我的算法是正确的。
### 内置习题
![内置习题_内置习题_理解梯度检验](amWiki/images/001/05-Week5/1-Neural Networks Learning/26-内置习题_理解梯度检验.jpg)
![为什么选择反向传播算法而不是梯度检测去实现](amWiki/images/001/05-Week5/1-Neural Networks Learning/27-内置习题_为什么选择反向传播算法而不是梯度检测去实现.jpg)
## English
### Θ is a vector, the Gradient Checking
![Θ is a vector, the Gradient Checking](amWiki/images/001/05-Week5/1-Neural Networks Learning/22-当 Θ 是一个向量时的梯度检验.jpg)  
In the last few videos we talked about how to do forward propagation and back propagation in a neural network in order to compute derivatives. But back prop as an algorithm has a lot of details and can be a little bit tricky to implement. And one unfortunate property is that there are many ways to have subtle bugs in back prop. So that if you run it with gradient descent or some other optimizational algorithm, it could actually look like it's working. And your cost function, J of theta may end up decreasing on every iteration of gradient descent. But this could prove true even though there might be some bug in your implementation of back prop. So that it looks J of theta is decreasing, but you might just wind up with a neural network that has a higher level of error than you would with a bug free implementation. And you might just not know that there was this subtle bug that was giving you worse performance. So, what can we do about this? There's an idea called gradient checking that eliminates almost all of these problems. So, today every time I implement back propagation or a similar gradient to a [INAUDIBLE] on a neural network or any other reasonably complex model, I always implement gradient checking. And if you do this, it will help you make sure and sort of gain high confidence that your implementation of four prop and back prop or whatever is 100% correct. And from what I've seen this pretty much eliminates all the problems associated with a sort of a buggy implementation as a back prop. And in the previous videos I asked you to take on faith that the formulas I gave for computing the deltas and the vs and so on, I asked you to take on faith that those actually do compute the gradients of the cost function. But once you implement numerical gradient checking, which is the topic of this video, you'll be able to absolute verify for yourself that the code you're writing does indeed, is indeed computing the derivative of the cross function J.So here's the idea, consider the following example. Suppose that I have the function J of theta and I have some value theta and for this example gonna assume that theta is just a real number. And let's say that I want to estimate the derivative of this function at this point and so the derivative is equal to the slope of that tangent one.Here's how I'm going to numerically approximate the derivative, or rather here's a procedure for numerically approximating the derivative. I'm going to compute theta plus epsilon, so now we move it to the right. And I'm gonna compute theta minus epsilon and I'm going to look at those two points, And connect them by a straight line And I'm gonna connect these two points by a straight line, and I'm gonna use the slope of that little red line as my approximation to the derivative. Which is, the true derivative is the slope of that blue line over there. So, you know it seems like it would be a pretty good approximation.Mathematically, the slope of this red line is this vertical height divided by this horizontal width. So this point on top is the J of (Theta plus Epsilon). This point here is J (Theta minus Epsilon), so this vertical difference is J (Theta plus Epsilon) minus J of theta minus epsilon and this horizontal distance is just 2 epsilon. So my approximation is going to be that the derivative respect of theta of J of theta at this value of theta, that that's approximately J of theta plus epsilon minus J of theta minus epsilon over 2 epsilon.Usually, I use a pretty small value for epsilon, expect epsilon to be maybe on the order of 10 to the minus 4. There's usually a large range of different values for epsilon that work just fine. And in fact, if you let epsilon become really small, then mathematically this term here, actually mathematically, it becomes the derivative. It becomes exactly the slope of the function at this point. It's just that we don't want to use epsilon that's too, too small, because then you might run into numerical problems. So I usually use epsilon around ten to the minus four. And by the way some of you may have seen an alternative formula for s meeting the derivative which is this formula.This one on the right is called a one-sided difference, whereas the formula on the left, that's called a two-sided difference. The two sided difference gives us a slightly more accurate estimate, so I usually use that, rather than this one sided difference estimate.So, concretely, when you implement an octave, is you implemented the following, you implement call to compute gradApprox, which is going to be our approximation derivative as just here this formula, J of theta plus epsilon minus J of theta minus epsilon divided by 2 times epsilon. And this will give you a numerical estimate of the gradient at that point. And in this example it seems like it's a pretty good estimate.
### Θ is a matrice, the Gradient Checking
![Θ is a matrice, the Gradient Checking](amWiki/images/001/05-Week5/1-Neural Networks Learning/23-当 Θ 是一个矩阵时的梯度检验.jpg)  
Now on the previous slide, we considered the case of when theta was a rolled number. Now let's look at a more general case of when theta is a vector parameter, so let's say theta is an R n. And it might be an unrolled version of the parameters of our neural network. So theta is a vector that has n elements, theta 1 up to theta n. We can then use a similar idea to approximate all the partial derivative terms. Concretely the partial derivative of a cost function with respect to the first parameter, theta one, that can be obtained by taking J and increasing theta one. So you have J of theta one plus epsilon and so on. Minus J of this theta one minus epsilon and divide it by two epsilon. The partial derivative respect to the second parameter theta two, is again this thing except that you would take J of here you're increasing theta two by epsilon, and here you're decreasing theta two by epsilon and so on down to the derivative. With respect of theta n would give you increase and decrease theta and by epsilon over there.So, these equations give you a way to numerically approximate the partial derivative of J with respect to any one of your parameters theta i.
Completely, what you implement is therefore the following.
### Implement the Gradient Checking  in the Octave
![Implement the Gradient Checking  in the Octave](amWiki/images/001/05-Week5/1-Neural Networks Learning/24-在Octave中实现梯度检验代码.jpg)  
We implement the following in octave to numerically compute the derivatives. We say, for i = 1:n, where n is the dimension of our parameter of vector theta. And I usually do this with the unrolled version of the parameter. So theta is just a long list of all of my parameters in my neural network, say. I'm gonna set thetaPlus = theta, then increase thetaPlus of the (i) element by epsilon. And so this is basically thetaPlus is equal to theta except for thetaPlus(i) which is now incremented by epsilon. Epsilon, so theta plus is equal to, write theta 1, theta 2 and so on. Then theta I has epsilon added to it and then we go down to theta N. So this is what theta plus is. And similar these two lines set theta minus to something similar except that this instead of theta I plus Epsilon, this now becomes theta I minus Epsilon.And then finally you implement this gradApprox (i) and this would give you your approximation to the partial derivative respect of theta i of J of theta.And the way we use this in our neural network implementation is, we would implement this four loop to compute the top partial derivative of the cost function for respect to every parameter in that network, and we can then take the gradient that we got from backprop. So DVec was the derivative we got from backprop. All right, so backprop, backpropogation, was a relatively efficient way to compute a derivative or a partial derivative. Of a cost function with respect to all our parameters. And what I usually do is then, take my numerically computed derivative that is this gradApprox that we just had from up here. And make sure that that is equal or approximately equal up to small values of numerical round up, that it's pretty close. So the DVec that I got from backprop. And if these two ways of computing the derivative give me the same answer, or give me any similar answers, up to a few decimal places, then I'm much more confident that my implementation of backprop is correct. And when I plug these DVec vectors into gradient assent or some advanced optimization algorithm, I can then be much more confident that I'm computing the derivatives correctly, and therefore that hopefully my code will run correctly and do a good job optimizing J of theta.
### Notice of Back propagation algorithm in Gradient Checking
![Notice of Back propagation algorithm in Gradient Checking](amWiki/images/001/05-Week5/1-Neural Networks Learning/25-反向传播算法中梯度检验注意细节.jpg)  
Finally, I wanna put everything together and tell you how to implement this numerical gradient checking. Here's what I usually do. First thing I do is implement back propagation to compute DVec. So there's a procedure we talked about in the earlier video to compute DVec which may be our unrolled version of these matrices. So then what I do, is implement a numerical gradient checking to compute gradApprox. So this is what I described earlier in this video and in the previous slide.Then should make sure that DVec and gradApprox give similar values, you know let's say up to a few decimal places.And finally and this is the important step, before you start to use your code for learning, for seriously training your network, it's important to turn off gradient checking and to no longer compute this gradApprox thing using the numerical derivative formulas that we talked about earlier in this video.And the reason for that is the numeric code gradient checking code, the stuff we talked about in this video, that's a very computationally expensive, that's a very slow way to try to approximate the derivative. Whereas In contrast, the back propagation algorithm that we talked about earlier, that is the thing we talked about earlier for computing. You know, D1, D2, D3 for Dvec. Backprop is much more computationally efficient way of computing for derivatives.So once you've verified that your implementation of back propagation is correct, you should turn off gradient checking and just stop using that. So just to reiterate, you should be sure to disable your gradient checking code before running your algorithm for many iterations of gradient descent or for many iterations of the advanced optimization algorithms, in order to train your classifier. Concretely, if you were to run the numerical gradient checking on every single iteration of gradient descent. Or if you were in the inner loop of your costFunction, then your code would be very slow. Because the numerical gradient checking code is much slower than the backpropagation algorithm, than the backpropagation method where, you remember, we were computing delta(4), delta(3), delta(2), and so on. That was the backpropagation algorithm. That is a much faster way to compute derivates than gradient checking. So when you're ready, once you've verified the implementation of back propagation is correct, make sure you turn off or you disable your gradient checking code while you train your algorithm, or else you code could run very slowly.So, that's how you take gradients numericaly, and that's how you can verify tha implementation of back propagation is correct. Whenever I implement back propagation or similar gradient discerning algorithm for a complicated mode,l I always use gradient checking and this really helps me make sure that my code is correct.
### Exam_in the video
![Exam_Understand Gradient Checking](amWiki/images/001/05-Week5/1-Neural Networks Learning/26-内置习题_理解梯度检验.jpg)
![Exam_Why did you choose back propagation algorithm instead of Gradient Checking to implement](amWiki/images/001/05-Week5/1-Neural Networks Learning/27-内置习题_为什么选择反向传播算法而不是梯度检测去实现.jpg)
