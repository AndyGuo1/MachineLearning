# 神经网络学习- 整合之前所学
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/05-Week5/1-Neural Networks Learning/7-Putting It Together.mp4" type="video/mp4">
</video>
## 中文
### 搭建神经网络模型
![搭建神经网络模型](amWiki/images/001/05-Week5/1-Neural Networks Learning/34-搭建神经网络模型.jpg)
我们已经用了 几节视频的内容 来介绍神经网络算法 在这段视频中 我想结合我们所讲的 所有这些内容 来做一个总体的回顾 看看这些零散的内容 相互之间有怎样的联系 以及神经网络学习算法的 总体实现过程 当我们在训练一个神经网络时 我们要做的第一件事 就是搭建网络的大体框架 这里我说的框架 意思是 神经元之间的连接模式 我们可能会从以下几种结构中选择 第一种神经网络的结构是 包含三个输入单元 五个隐藏单元 和四个输出单元 第二种结构是 三个输入单元作为输入层 两组五个隐藏单元作为隐藏层 四个输出单元的输出层 然后第三种是3 5 5 5 其中每个隐藏层包含五个单元 然后是四个输出单元 这些就是可能选择的结构 每一层可以选择 多少个隐藏单元 以及可以选择多少个隐藏层 这些都是你构建时的选择 那么我们该如何做出选择呢？首先 我们知道 我们已经定义了输入单元的数量 一旦你确定了特征集x 对应的输入单元数目 也就确定了 也就是等于特征x{i}的维度 输入单元数目将会由此确定 如果你正在进行 多类别分类 那么输出层的单元数目 将会由你分类问题中 所要区分的类别个数确定 值得提醒的是 如果你的多元分类问题 y的取值范围是在1到10之间 那么你就有10个可能的分类 别忘了把你的y 重新写成向量的形式 所以现在我们的y不是一个数了 我们重新把y写成 这种形式的向量 第二个分类我们可以写成这样的向量 所以 比如说 如果要表达 第五个分类 也就是说y等于5 那么在你的神经网络中 就不能直接用 数值5来表达 因为这里的输出层 有十个输出单元 你应该用一个向量 来表示这个向量的第五个位置值是1 其它的都是0 所以对于输入单元 和输出单元数目的选择 还是比较容易理解的 而对于隐藏单元的个数 单元的个数 以及隐藏层的数目 我们有一个默认的规则 那就是只使用单个隐藏层 所以最左边所示的 这种只有一个隐藏层的神经网络 一般来说是最普遍的 或者如果你使用 不止一个隐藏层的话 同样我们也有一个默认规则 那就是每一个隐藏层 通常都应有相同的单元数 所以对于这个结构 我们有两个隐藏层 每个隐藏层都有相同的单元数 都是5个隐藏单元 这里也是一样 我们有三个隐藏层 每个隐藏层有相同的单元数 都是5个隐藏单元 但实际上通常来说 左边这个结构是较为合理的默认结构 而对于隐藏单元的个数 通常情况下 隐藏单元越多越好 不过 我们需要注意的是 如果有大量隐藏单元 计算量一般会比较大 当然 一般来说隐藏单元还是越多越好 并且一般来说 每个隐藏层 所包含的单元数量 还应该和输入x 的维度相匹配 也要和特征的数目匹配 可能隐藏单元的数目 和输入特征的数量相同 或者是它的二倍 或者三倍 四倍 因此 隐藏单元的数目需要和其他参数相匹配 一般来说 隐藏单元的数目取为稍大于 输入特征数目 都是可以接受的 希望这些能够给你 在选择神经网络结构时 提供一些有用的建议和选择的参考 如果你遵循了这些建议 你一般会得到比较好的模型结构 但是 在以后的一系列视频中 特别是在我谈到 学习算法的应用时 我还会更详细地介绍 如何选择神经网络的结构 后面的视频中 我还会着重介绍 怎样正确地选择隐藏层的个数 以及隐藏单元的数目 等等
### 神经网络训练过程的6大步骤.
![神经网络训练过程的6大步骤.](amWiki/images/001/05-Week5/1-Neural Networks Learning/35-神经网络训练过程的6大步骤.jpg)
下面我们就来具体介绍 如何实现神经网络的 训练过程 这里一共有六个步骤 这页幻灯片中罗列了前四步 剩下的两步 放在下一张幻灯片中 首先 第一步是构建一个 神经网络 然后随机初始化权值 通常我们把权值 初始化为很小的值 接近于零 然后我们执行前向传播算法 也就是 对于该神经网络的 任意一个输入x(i) 计算出对应的h(x)值 也就是一个输出值y的向量 接下来我们通过代码 计算出代价函数J(θ) 然后我们执行 反向传播算法来算出这些偏导数 或偏微分项 也就是 J(θ)关于参数θ的偏微分 具体来说 我们要对所有训练集数据 使用一个for循环进行遍历可能有部分同学之前听说过 一些比较先进的分解方法 可能不需要像这里一样使用 for循环来对所有 m个训练样本进行遍历 但是 这是你第一次进行反向传播算法 所以我建议你最好还是 使用一个for循环来完成程序 对每一个训练样本进行迭代 从x(1) y(1)开始 我们对第一个样本进行 前向传播运算和反向传播运算 然后在第二次循环中 同样地对第二个样本 执行前向传播和反向传播算法 以此类推 直到最后一个样本 因此 在你第一次做反向传播的时候 你还是应该用这样的for循环 来实现这个过程 其实实际上 有复杂的方法可以实现 并不一定要使用for循环 但我非常不推荐 在第一次实现反向传播算法的时候 使用更复杂更高级的方法所以具体来讲 我们对所有的 m个训练样本上使用了for循环遍历在这个for循环里 我们对每个样本执行 前向和反向算法具体来说就是 我们把x(i) 传到输入层 然后执行前向传播和反向传播 这样我们就能得到 该神经网络中 每一层中每一个单元对应的 所有这些激励值a(l) 和delta项 接下来 还是在for循环中 让我画一个大括号 来标明这个 for循环的范围 当然这些是octave的代码 括号里是for循环的循环体 我们要计算出这些delta值 也就是用我们之前给出的公式加上 delta(l+1) a(l)的转置矩阵 最后 外面的部分 计算出的这些delta值 这些累加项 我们将用别的程序 来计算出 这些偏导数项 那么这些偏导数项 也应该考虑使用 正则化项lambda值 这些公式在前面的视频中已经给出 那么 搞定所有这些内容 现在你就应该已经得到了 计算这些偏导数项的程序了
![神经网络训练过程的6大步骤](amWiki/images/001/05-Week5/1-Neural Networks Learning/36-神经网络训练过程的6大步骤.jpg)
下面就是第五步了 我要做的就是使用梯度检查 来比较这些 已经计算得到的偏导数项 把用反向传播算法 得到的偏导数值 与用数值方法得到的估计值进行比较 因此 通过进行梯度检查来 确保两种方法得到基本接近的两个值通过梯度检查我们能确保 我们的反向传播算法 得到的结果是正确的 但必须要说明的一点是 我们需要去掉梯度检查的代码 因为梯度检查的计算非常慢 最后 我们就可以 使用一个最优化算法 比如说梯度下降算法 或者说是更加高级的优化方法 比如说BFGS算法 共轭梯度法 或者其他一些已经内置到fminunc函数中的方法 将所有这些优化方法 和反向传播算法相结合 这样我们就能计算出 这些偏导数项的值 到现在 我们已经知道了 如何去计算代价函数 我们知道了如何使用 反向传播算法来计算偏导数 那么 我们就能使用某个最优化方法 来最小化关于theta的函数值 代价函数J(θ) 另外顺便提一下 对于神经网络 代价函数 J(θ)是一个非凸函数 就是说不是凸函数 因此理论上是能够停留在 局部最小值的位置 实际上 梯度下降算法 和其他一些高级优化方法 理论上都能收敛于局部最小值 但一般来讲 这个问题其实 并不是什么要紧的事 尽管我们不能保证 这些优化算法一定会得到 全局最优值 但通常来讲 像梯度下降这类的算法 在最小化代价函数 J(θ)的过程中 还是表现得很不错的 通常能够得到一个很小的局部最小值 尽管这可能不一定是全局最优值
### 通过图片理解反向传播算法使用梯度下降基本原理
![通过图片理解反向传播算法使用梯度下降基本原理](amWiki/images/001/05-Week5/1-Neural Networks Learning/37-通过图片理解反向传播算法使用梯度下降基本原理.jpg)
最后 梯度下降算法 似乎对于神经网络来说还是比较神秘 希望下面这幅图 能让你对梯度下降法在神经网络中的应用 产生一个更直观的理解 这实际上有点类似 我们早先时候解释梯度下降时的思路 我们有某个代价函数 并且在我们的神经网络中 有一系列参数值 这里我只写下了两个参数值 当然实际上 在神经网络里 我们可以有很多的参数值 theta1 theta2 等等 所有的这些都是矩阵 是吧 因此我们参数的维度就会很高了 由于绘图所限 我们不能绘出 更高维度情况的图像 所以这里我们假设 这个神经网络中只有两个参数值 实际上应该有更多参数 那么 代价函数J(θ) 度量的就是这个神经网络 对训练数据的拟合情况 所以 如果你取某个参数 比如说这个 下面这点 在这个点上 J(θ) 的值是非常小的 这一点的位置所对应的 参数theta的情况是 对于大部分 的训练集数据 我的假设函数的输出 会非常接近于y(i) 那么如果是这样的话 那么我们的代价函数值就会很小而反过来 如果我们 取这个值 也就是这个点对应的值 那么对于大部分的训练集样本 该神经网络的输出 应该是远离 y(i)的实际值的 也就是我们在训练集观测到的输出值 因此 像这样的点 右边的这个点 对应的假设就是 神经网络的输出值 在这个训练集上的测试值 应该是远离y(i)的 因此这一点对应着对训练集拟合得不好的情况 而像这些点 代价函数值很小的点 对应的J(θ)值 是很小的 因此对应的是 神经网络对训练集数据 拟合得比较好的情况 我想表达的是 如果是这种情况的话 那么J(θ)的值应该是比较小的 因此梯度下降算法的原理是 我们从某个随机的 初始点开始 比如这一点 它将会不停的往下下降 那么反向传播算法 的目的就是算出 梯度下降的方向 而梯度下降的过程 就是沿着这个方向 一点点的下降 一直到我们希望得到的点 在这里我们希望找到的就是局部最优点 所以 当你在执行反向传播算法 并且使用梯度下降 或者 更高级的优化方法时 这幅图片很好地帮你解释了基本的原理 也就是 试图找到某个最优的参数值 这个值使得 我们神经网络的输出值 与y(i)的实际值 也就是训练集的输出观测值 尽可能的接近 希望这节课的内容能让你对 这些零散的神经网络知识 如何有机地结合起来 能有一个更直观的认识 但可能你即使看了这段视频 你可能还是觉得 有许多的细节 不能完全明白 为什么这么做 或者说是这些是如何 联系在一起的 没关系 神经网络和反向传播算法本身就是非常复杂的算法 尽管我已经完全理解了 反向传播算法背后的数学原理 尽管我使用反向传播已经很多年了 我认为 这么多年的使用还算是成功的 但尽管如此 到现在我还是觉得 我自己也并不是总能 很好地理解反向传播到底在做什么 以及最优化过程是如何 使J(θ)值达到最小值的 因为这本身的确是一个很难的算法 很难让你感觉到 自己已经完全理解 它不像线性回归 或者逻辑回归那样 数学上和概念上都很简单 反向传播算法不是那样的直观 如果你也有同感 那么完全不必担心 但如果你自己动手 完成一次反向传播算法 你一定会发现 这的确是一个很强大的 学习算法 如果你 执行一下这个算法 执行反向传播 执行其中的优化方法 你一定会发现 反向传播算法能够很好的 让更复杂 维度更大的 非线性的 函数模型跟你的数据很好地拟合 因此它的确是一种 最为高效的学习算法
### 内置习题
![内置习题_理解参数初始化](amWiki/images/001/05-Week5/1-Neural Networks Learning/38-内置习题_理解反向传播算法中使用梯度下降.jpg)
## English
### Pick a network architecture
![Pick a network architecture](amWiki/images/001/05-Week5/1-Neural Networks Learning/34-搭建神经网络模型.jpg)
So, it's taken us a lot of videos to get through the neural network learning algorithm.In this video, what I'd like to do is try to put all the pieces together, to give a overall summary or a bigger picture view, of how all the pieces fit together and of the overall process of how to implement a neural network learning algorithm.When training a neural network, the first thing you need to do is pick some network architecture and by architecture I just mean connectivity pattern between the neurons. So, you know, we might choose between say, a neural network with three input units and five hidden units and four output units versus one of 3, 5 hidden, 5 hidden, 4 output and here are 3, 5, 5, 5 units in each of three hidden layers and four open units, and so these choices of how many hidden units in each layer and how many hidden layers, those are architecture choices. So, how do you make these choices?Well first, the number of input units well that's pretty well defined. And once you decides on the fix set of features x the number of input units will just be, you know, the dimension of your features x(i) would be determined by that. And if you are doing multiclass classifications the number of output of this will be determined by the number of classes in your classification problem. And just a reminder if you have a multiclass classification where y takes on say values between 1 and 10, so that you have ten possible classes.Then remember to right, your output y as these were the vectors. So instead of clause one, you recode it as a vector like that, or for the second class you recode it as a vector like that. So if one of these apples takes on the fifth class, you know, y equals 5, then what you're showing to your neural network is not actually a value of y equals 5, instead here at the upper layer which would have ten output units, you will instead feed to the vector which you know with one in the fifth position and a bunch of zeros down here. So the choice of number of input units and number of output units is maybe somewhat reasonably straightforward.And as for the number of hidden units and the number of hidden layers, a reasonable default is to use a single hidden layer and so this type of neural network shown on the left with just one hidden layer is probably the most common.Or if you use more than one hidden layer, again the reasonable default will be to have the same number of hidden units in every single layer. So here we have two hidden layers and each of these hidden layers have the same number five of hidden units and here we have, you know, three hidden layers and each of them has the same number, that is five hidden units.Rather than doing this sort of network architecture on the left would be a perfect ably reasonable default.And as for the number of hidden units - usually, the more hidden units the better; it's just that if you have a lot of hidden units, it can become more computationally expensive, but very often, having more hidden units is a good thing.And usually the number of hidden units in each layer will be maybe comparable to the dimension of x, comparable to the number of features, or it could be any where from same number of hidden units of input features to maybe so that three or four times of that. So having the number of hidden units is comparable. You know, several times, or some what bigger than the number of input features is often a useful thing to do So, hopefully this gives you one reasonable set of default choices for neural architecture and and if you follow these guidelines, you will probably get something that works well, but in a later set of videos where I will talk specifically about advice for how to apply algorithms, I will actually say a lot more about how to choose a neural network architecture. Or actually have quite a lot I want to say later to make good choices for the number of hidden units, the number of hidden layers, and so on.
### Six steps in the process of neural network training
![Six steps in the process of neural network training](amWiki/images/001/05-Week5/1-Neural Networks Learning/35-神经网络训练过程的6大步骤.jpg)
Next, here's what we need to implement in order to trade in neural network, there are actually six steps that I have; I have four on this slide and two more steps on the next slide. First step is to set up the neural network and to randomly initialize the values of the weights. And we usually initialize the weights to small values near zero.Then we implement forward propagation so that we can input any excellent neural network and compute h of x which is this output vector of the y values.We then also implement code to compute this cost function j of theta.And next we implement back-prop, or the back-propagation algorithm, to compute these partial derivatives terms, partial derivatives of j of theta with respect to the parameters. Concretely, to implement back prop. Usually we will do that with a fore loop over the training examples.Some of you may have heard of advanced, and frankly very advanced factorization methods where you don't have a four-loop over the m-training examples, that the first time you're implementing back prop there should almost certainly the four loop in your code, where you're iterating over the examples, you know, x1, y1, then so you do forward prop and back prop on the first example, and then in the second iteration of the four-loop, you do forward propagation and back propagation on the second example, and so on. Until you get through the final example. So there should be a four-loop in your implementation of back prop, at least the first time implementing it. And then there are frankly somewhat complicated ways to do this without a four-loop, but I definitely do not recommend trying to do that much more complicated version the first time you try to implement back prop.So concretely, we have a four-loop over my m-training examples and inside the four-loop we're going to perform fore prop and back prop using just this one example.And what that means is that we're going to take x(i), and feed that to my input layer, perform forward-prop, perform back-prop and that will if all of these activations and all of these delta terms for all of the layers of all my units in the neural network then still inside this four-loop, let me draw some curly braces just to show the scope with the four-loop, this is in octave code of course, but it's more a sequence Java code, and a four-loop encompasses all this. We're going to compute those delta terms, which are is the formula that we gave earlier.Plus, you know, delta l plus one times a, l transpose of the code. And then finally, outside the having computed these delta terms, these accumulation terms, we would then have some other code and then that will allow us to compute these partial derivative terms. Right and these partial derivative terms have to take into account the regularization term lambda as well. And so, those formulas were given in the earlier video.So, how do you done that you now hopefully have code to compute these partial derivative terms.
![Six steps in the process of neural network training](amWiki/images/001/05-Week5/1-Neural Networks Learning/36-神经网络训练过程的6大步骤.jpg)
Next is step five, what I do is then use gradient checking to compare these partial derivative terms that were computed. So, I've compared the versions computed using back propagation versus the partial derivatives computed using the numerical estimates as using numerical estimates of the derivatives. So, I do gradient checking to make sure that both of these give you very similar values.Having done gradient checking just now reassures us that our implementation of back propagation is correct, and is then very important that we disable gradient checking, because the gradient checking code is computationally very slow.And finally, we then use an optimization algorithm such as gradient descent, or one of the advanced optimization methods such as LB of GS, contract gradient has embodied into fminunc or other optimization methods. We use these together with back propagation, so back propagation is the thing that computes these partial derivatives for us.And so, we know how to compute the cost function, we know how to compute the partial derivatives using back propagation, so we can use one of these optimization methods to try to minimize j of theta as a function of the parameters theta. And by the way, for neural networks, this cost function j of theta is non-convex, or is not convex and so it can theoretically be susceptible to local minima, and in fact algorithms like gradient descent and the advance optimization methods can, in theory, get stuck in local optima, but it turns out that in practice this is not usually a huge problem and even though we can't guarantee that these algorithms will find a global optimum, usually algorithms like gradient descent will do a very good job minimizing this cost function j of theta and get a very good local minimum, even if it doesn't get to the global optimum.
### An image to understand basic principle of back propagation algorithm with gradient descent
![An image to understand basic principle of back propagation algorithm with gradient descent](amWiki/images/001/05-Week5/1-Neural Networks Learning/37-通过图片理解反向传播算法使用梯度下降基本原理.jpg)
Finally, gradient descents for a neural network might still seem a little bit magical. So, let me just show one more figure to try to get that intuition about what gradient descent for a neural network is doing.This was actually similar to the figure that I was using earlier to explain gradient descent. So, we have some cost function, and we have a number of parameters in our neural network. Right here I've just written down two of the parameter valuesimage understanding basic principle of back propagation algorithm using gradient descent. In reality, of course, in the neural network, we can have lots of parameters with these. Theta one, theta two--all of these are matrices, right? So we can have very high dimensional parameters but because of the limitations the source of parts we can draw. I'm pretending that we have only two parameters in this neural network. Although obviously we have a lot more in practice.Now, this cost function j of theta measures how well the neural network fits the training data.So, if you take a point like this one, down here,that's a point where j of theta is pretty low, and so this corresponds to a setting of the parameters. There's a setting of the parameters theta, where, you know, for most of the training examples, the output of my hypothesis, that may be pretty close to y(i) and if this is true than that's what causes my cost function to be pretty low.Whereas in contrast, if you were to take a value like that, a point like that corresponds to, where for many training examples, the output of my neural network is far from the actual value y(i) that was observed in the training set. So points like this on the line correspond to where the hypothesis, where the neural network is outputting values on the training set that are far from y(i). So, it's not fitting the training set well, whereas points like this with low values of the cost function corresponds to where j of theta is low, and therefore corresponds to where the neural network happens to be fitting my training set well, because I mean this is what's needed to be true in order for j of theta to be small.So what gradient descent does is we'll start from some random initial point like that one over there, and it will repeatedly go downhill.And so what back propagation is doing is computing the direction of the gradient, and what gradient descent is doing is it's taking little steps downhill until hopefully it gets to, in this case, a pretty good local optimum.So, when you implement back propagation and use gradient descent or one of the advanced optimization methods, this picture sort of explains what the algorithm is doing. It's trying to find a value of the parameters where the output values in the neural network closely matches the values of the y(i)'s observed in your training set. So, hopefully this gives you a better sense of how the many different pieces of neural network learning fit together.In case even after this video, in case you still feel like there are, like, a lot of different pieces and it's not entirely clear what some of them do or how all of these pieces come together, that's actually okay.Neural network learning and back propagation is a complicated algorithm.And even though I've seen the math behind back propagation for many years and I've used back propagation, I think very successfully, for many years, even today I still feel like I don't always have a great grasp of exactly what back propagation is doing sometimes. And what the optimization process looks like of minimizing j if theta. Much this is a much harder algorithm to feel like I have a much less good handle on exactly what this is doing compared to say, linear regression or logistic regression.Which were mathematically and conceptually much simpler and much cleaner algorithms.But so in case if you feel the same way, you know, that's actually perfectly okay, but if you do implement back propagation, hopefully what you find is that this is one of the most powerful learning algorithms and if you implement this algorithm, implement back propagation, implement one of these optimization methods, you find that back propagation will be able to fit very complex, powerful, non-linear functions to your data, and this is one of the most effective learning algorithms we have today.
### Exam_in the video
![Exam_Understand back propagation algorithm with gradient descent](amWiki/images/001/05-Week5/1-Neural Networks Learning/38-内置习题_理解反向传播算法中使用梯度下降.jpg)
