# 神经网络学习- 随机初始化参数Θ
## 视频
<video height=510 width=900 controls="controls" preload="none">
      <source src="amWiki/videos/001/05-Week5/1-Neural Networks Learning/6-Random Initialization.mp4" type="video/mp4">
</video>
## 中文
### 初始化参数 Θ 值
![初始化参数 Θ 值](amWiki/images/001/05-Week5/1-Neural Networks Learning/29-初始化参数 Θ 值.jpg)
在之前的视频里，我们总结了所有内容 来帮助你应用 这是最后一个视频 关于随机初始化。当你使用梯度下降算法， 或者其他高级的优化算法，我们需要设置初始值 恩 所以，对于高级的优化算法 假设你是有一个初始值 现在我们假设就是梯度下降 为此， 通过初值，我们之后一步步通过梯度下降走到山坡底部 当然，这里就是求最小值 所以，我们怎么设置呢 能不能就全部是零呢 这在之前的逻辑回归里可行 全部为零是可以的 恩。
### 神经网络中直接将参数 Θ 初始化为0或者0矩阵会出现的问题
![神经网络中直接将参数 Θ 初始化为0或者0矩阵会出现的问题](amWiki/images/001/05-Week5/1-Neural Networks Learning/30-神经网络中直接将参数 Θ 初始化为0或者0矩阵会出现的问题.jpg)
假设我们现在有这么一个网络， 假设全部参数为0 恩，如果你这么做 可以看到蓝色的权值，全是0 我用红色标记的， 等于这个权值 用绿色标记的也等于它 所以，对于A1和A2隐层单元 将会用同一个函数计算 结果， A21等于A22 此外，因为 这输出的权值 你可以发现他们的误差值也一样 所以，结果delta11 delta21等于delta22 所以，如果继续下去 我们可以发现他满足下述情况 即所有的偏导数 就编程这两条蓝色的波浪线 你会发现他们都一样。 得知植物能闻到彼此时一定很惊讶恩 也就是说， 你会发现， 更新的时候 通过计算梯度，更新的结果 这两个参数是一样。 所以，会得到非零的值，但这个值会相等 相似的， 即使是通过梯度下降算法，结果也是相等 可能有一些非零的结果 就是红色的箱单 类似绿色也相等 他们都改变结果 但是结果都是一样的 所以每一次更新，参数对应的结果 都是完全一致 这和前面所说的一样， 红色、绿色、蓝色都一样， 这意味着什么呢 你会发现，两个单元仍然计算同样的结果 恩 你仍然有a1(2)=a2(2) 回到原点。 所以，你不断计算 不断计算，都是一样 红色的情况也是 绿色的也是 所以， 你的神经网络实际上进入很有意思的情况 相信，你不仅有两个隐层， 二是有很多很多层 那么 这将是同样的特性。 所有你的隐层的结果都一样 这是非常冗余的 因为，你发现是逻辑回归 本质上只有一个特征 这就使得你的神经网络性能下降 无法进行更有意义的功能。 所以我们需要随机初始化
### 随机初始化参数 Θ 是为了打破平衡
![随机初始化参数 Θ 是为了打破平衡](amWiki/images/001/05-Week5/1-Neural Networks Learning/31-随机初始化参数 Θ 是为了打破平衡.jpg)
具体来说，我们之前看到的问题 叫做对称现象 所以，初始化也被称作打破对称 所以我们进行初始化的操作目的就是 打破对称，而初始区间就是在特定范围内 这是一种我们用的标记。 所以，我的权值参数 将会在这个范围内生成。 这是我们写代码采用的方式1 恩 rand10通过11 这是你如何计算随机的10乘11矩阵 所有的值都在0到1 这是连续的0到1的值 所以， 你再乘以这两个参数 你会得到最后满足区间要求的结果 这是生成特定区间随机数常用的计算操作 这里的epsilon和梯度检验的epsilon是两码事情 不要混淆 这只是一个符号数字而已 完全没有关联。 只是喜欢用epsilon来表示而已 这里我们可以区别他们。 类似的，如果你想要初始化theta2为一个1乘11 的矩阵，你可以用这个代码原理是一样的 不再赘述 -epsilon到+epsilon范围 然后你再使用反向传播， 使用梯度检验，1b 在()从头开始进行计算 随机初始化结果 也就是打破对称 希望， 这个梯度下降算法或者更高级的优化算法能够找到这个理想的theta值。
### 内置习题
![内置习题_理解参数初始化](amWiki/images/001/05-Week5/1-Neural Networks Learning/32-内置习题_理解参数初始化.jpg)
## English
### Initial value of Θ
![Initial value of Θ](amWiki/images/001/05-Week5/1-Neural Networks Learning/29-初始化参数 Θ 值.jpg)
In the previous video, we've put together almost all the pieces you need in order to implement and train in your network. There's just one last idea I need to share with you, which is the idea of random initialization.When you're running an algorithm of gradient descent, or also the advanced optimization algorithms, we need to pick some initial value for the parameters theta. So for the advanced optimization algorithm, it assumes you will pass it some initial value for the parameters theta.Now let's consider a gradient descent. For that, we'll also need to initialize theta to something, and then we can slowly take steps to go downhill using gradient descent. To go downhill, to minimize the function j of theta. So what can we set the initial value of theta to? Is it possible to set the initial value of theta to the vector of all zeros? Whereas this worked okay when we were using logistic regression.
### The problem of Neural network initialized Θ to 0 or 0 matrix
![The problem of Neural network initialized Θ to 0 or 0 matrix](amWiki/images/001/05-Week5/1-Neural Networks Learning/30-神经网络中直接将参数 Θ 初始化为0或者0矩阵会出现的问题.jpg)
Initializing all of your parameters to zero actually does not work when you are trading on your own network. Consider trading the follow Neural network, and let's say we initialize all the parameters of the network to 0. And if you do that, then what you, what that means is that at the initialization, this blue weight, colored in blue is gonna equal to that weight, so they're both 0. And this weight that I'm coloring in in red, is equal to that weight, colored in red, and also this weight, which I'm coloring in green is going to equal to the value of that weight. And what that means is that both of your hidden units, A1 and A2, are going to be computing the same function of your inputs. And thus you end up with for every one of your training examples, you end up with A 2 1 equals A 2 2.And moreover because I'm not going to show this in too much detail, but because these outgoing weights are the same you can also show that the delta values are also gonna be the same. So concretely you end up with delta 1 1, delta 2 1 equals delta 2 2, and if you work through the map further, what you can show is that the partial derivatives with respect to your parameters will satisfy the following, that the partial derivative of the cost function with respected to breaking out the derivatives respect to these two blue waves in your network. You find that these two partial derivatives are going to be equal to each other.And so what this means is that even after say one greater descent update, you're going to update, say, this first blue rate was learning rate times this, and you're gonna update the second blue rate with some learning rate times this. And what this means is that even after one created the descent update, those two blue rates, those two blue color parameters will end up the same as each other. So there'll be some nonzero value, but this value would equal to that value. And similarly, even after one gradient descent update, this value would equal to that value. There'll still be some non-zero values, just that the two red values are equal to each other. And similarly, the two green ways. Well, they'll both change values, but they'll both end up with the same value as each other. So after each update, the parameters corresponding to the inputs going into each of the two hidden units are identical. That's just saying that the two green weights are still the same, the two red weights are still the same, the two blue weights are still the same, and what that means is that even after one iteration of say, gradient descent and descent. You find that your two headed units are still computing exactly the same functions of the inputs. You still have the a1(2) = a2(2). And so you're back to this case. And as you keep running greater descent, the blue waves,, the two blue waves, will stay the same as each other. The two red waves will stay the same as each other and the two green waves will stay the same as each other.And what this means is that your neural network really can compute very interesting functions, right? Imagine that you had not only two hidden units, but imagine that you had many, many hidden units. Then what this is saying is that all of your headed units are computing the exact same feature. All of your hidden units are computing the exact same function of the input. And this is a highly redundant representation because you find the logistic progression unit. It really has to see only one feature because all of these are the same. And this prevents you and your network from doing something interesting. In order to get around this problem, the way we initialize the parameters of a neural network therefore is with random initialization.
### Random initialization Θ is to Symmetry Breaking
![Random initialization Θ is to Symmetry Breaking](amWiki/images/001/05-Week5/1-Neural Networks Learning/31-随机初始化参数 Θ 是为了打破平衡.jpg)
Concretely, the problem was saw on the previous slide is something called the problem of symmetric ways, that's the ways are being the same. So this random initialization is how we perform symmetry breaking. So what we do is we initialize each value of theta to a random number between minus epsilon and epsilon. So this is a notation to b numbers between minus epsilon and plus epsilon. So my weight for my parameters are all going to be randomly initialized between minus epsilon and plus epsilon. The way I write code to do this in octave is I've said Theta1 should be equal to this. So this rand 10 by 11, that's how you compute a random 10 by 11 dimensional matrix. All the values are between 0 and 1, so these are going to be raw numbers that take on any continuous values between 0 and 1. And so if you take a number between zero and one, multiply it by two times INIT_EPSILON then minus INIT_EPSILON, then you end up with a number that's between minus epsilon and plus epsilon.And the so that leads us, this epsilon here has nothing to do with the epsilon that we were using when we were doing gradient checking. So when numerical gradient checking, there we were adding some values of epsilon and theta. This is your unrelated value of epsilon. We just wanted to notate init epsilon just to distinguish it from the value of epsilon we were using in gradient checking. And similarly if you want to initialize theta2 to a random 1 by 11 matrix you can do so using this piece of code here.So to summarize, to create a neural network what you should do is randomly initialize the waves to small values close to zero, between -epsilon and +epsilon say. And then implement back propagation, do great in checking, and use either great in descent or 1b advanced optimization algorithms to try to minimize j(theta) as a function of the parameters theta starting from just randomly chosen initial value for the parameters. And by doing symmetry breaking, which is this process, hopefully great gradient descent or the advanced optimization algorithms will be able to find a good value of theta.
### Exam_in the video
![Exam_Understand initialization of Θ](amWiki/images/001/05-Week5/1-Neural Networks Learning/32-内置习题_理解参数初始化.jpg)
